<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Hamming-Enablers and The Tech In Techno-Optimism - part 1 | jared tumiel</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Hamming-Enablers and The Tech In Techno-Optimism - part 1" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Part 1 - Computation, Intelligence and Coordination + Progress, Institutions, and Politics" />
<meta property="og:description" content="Part 1 - Computation, Intelligence and Coordination + Progress, Institutions, and Politics" />
<link rel="canonical" href="https://jaredtumiel.github.io/blog/2021/08/06/techno-optimism1.html" />
<meta property="og:url" content="https://jaredtumiel.github.io/blog/2021/08/06/techno-optimism1.html" />
<meta property="og:site_name" content="jared tumiel" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-08-06T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Hamming-Enablers and The Tech In Techno-Optimism - part 1" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2021-08-06T00:00:00-05:00","datePublished":"2021-08-06T00:00:00-05:00","description":"Part 1 - Computation, Intelligence and Coordination + Progress, Institutions, and Politics","headline":"Hamming-Enablers and The Tech In Techno-Optimism - part 1","mainEntityOfPage":{"@type":"WebPage","@id":"https://jaredtumiel.github.io/blog/2021/08/06/techno-optimism1.html"},"url":"https://jaredtumiel.github.io/blog/2021/08/06/techno-optimism1.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://jaredtumiel.github.io/blog/feed.xml" title="jared tumiel" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-145017725-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-145017725-1');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">jared tumiel</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Hamming-Enablers and The Tech In Techno-Optimism - part 1</h1><p class="page-description">Part 1 - Computation, Intelligence and Coordination + Progress, Institutions, and Politics</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-08-06T00:00:00-05:00" itemprop="datePublished">
        Aug 6, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      26 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#hamming-enablers">Hamming Enablers</a></li>
<li class="toc-entry toc-h2"><a href="#computation-intelligence-and-coordination">Computation, Intelligence, and Coordination</a>
<ul>
<li class="toc-entry toc-h3"><a href="#heterogenous-compute-and-non-von-neumann-architectures">Heterogenous Compute, and Non-Von-Neumann architectures</a>
<ul>
<li class="toc-entry toc-h4"><a href="#beyond-electronic-compute">Beyond Electronic Compute</a></li>
<li class="toc-entry toc-h4"><a href="#beyond-von-neumann-compute">Beyond Von Neumann Compute</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#ai">AI</a></li>
<li class="toc-entry toc-h3"><a href="#crypto">Crypto</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#progress-institutions-and-politics">Progress, Institutions, and Politics</a>
<ul>
<li class="toc-entry toc-h3"><a href="#progress-studies--techno-optimism">Progress Studies &amp; Techno-Optimism</a></li>
<li class="toc-entry toc-h3"><a href="#parpa-new-science-focused-research-organisations-and-all-that">PARPA, New Science, Focused Research Organisations, and all that</a></li>
<li class="toc-entry toc-h3"><a href="#charter-cities">Charter Cities</a></li>
<li class="toc-entry toc-h3"><a href="#mechanism-design--social-technologies">Mechanism Design &amp; Social Technologies</a></li>
<li class="toc-entry toc-h3"><a href="#meaningness-and-meta-rationality">Meaningness, and meta-rationality</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#conclusion">Conclusion</a></li>
</ul><p>Robert Boyle (yes the one from high-school chemistry) kept a list of technologies he thought humanity should pursue:</p>

<p><img src="/blog/images/techno-optimism/boyle.jpg" alt="Robert Boyle's wishlist"></p>

<p>The list is surprisingly prescient, hinting at flying machines, submarines, life-extension, and psychedelics.</p>

<p>I too have a list (but alas, no highschoolers have heard of Tumiel’s Law) and this post is about that (the list, not the law). But first we have to talk about Hamming Enablers.</p>

<h2 id="hamming-enablers">
<a class="anchor" href="#hamming-enablers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hamming Enablers</h2>

<p>Boyle penned his list in the 1600s, which means that 300 years ago it was possible for a smart natural philosopher to conceive of these things being possible. So why the ~250 year delay between the list and the Wright Brothers? Why are psychedelics only really entering the (clinical) mainstream today? Why is human longevity not a solved problem already?</p>

<p>Each technology will have its own story of economic, scientific, design, and production challenges, but the general point I want to get at is the gap between technologies we can easily imagine (or suspect are possible), yet don’t currently know how to tackle.</p>

<p>The easiest way to understand this is through the idea of a tech-tree in video games: you can’t just unlock nuclear power if you haven’t first researched mining, uranium refinement, the physics of nuclear chain reactions, etc. It’s easy for anyone to look at birds flying and know that in-principle, heavier-than-air-flight is possible. It’s more difficult to backchain to what intermediate developments in fluid mechanics, calculus, materials science, and powertrain development are needed to build an aeroplane.</p>

<p><img src="/blog/images/techno-optimism/tech_tree.jpeg" alt="Civilisation's Tech Tree"></p>

<p><strong>So what’s a Hamming Enabler?</strong> Richard Hamming (of Bell Labs fame) in his famous speech <a href="https://www.cs.virginia.edu/~robins/YouAndYourResearch.html"><em>You and Your Research</em></a> has this to say:</p>

<blockquote>
  <p>Most great scientists know many important problems. They have something between 10 and 20 important problems for which they are looking for an attack. And when they see a new idea come up, one hears them say “Well that bears on this problem.’’ They drop all the other things and get after it.</p>
</blockquote>

<p>Gian-Carlo Rota, in his <a href="https://www.ams.org/notices/199701/comm-rota.pdf">advice to his younger colleagues</a>, quotes Richard Feynman, who offers a similar piece of advice:</p>

<blockquote>
  <p>Richard Feynman was fond of giving the following advice on how to be a genius. You have to keep a dozen of your favourite problems constantly present in your mind, although by and large they will lay in a dormant state. Every time you hear or read a new trick or a new result, test it against each of your twelve problems to see whether it helps. Every once in a while there will be a hit, and people will say, “How did he do it? He must be a genius!”</p>
</blockquote>

<p>And it’s not just dudes from the 1900s who think this is something worth doing! Here’s Ed Boyden<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> saying <a href="https://www.huffpost.com/entry/ed-boyden-how-to-think_n_57d6b584e4b03d2d459b4b50">much the same thing</a>:</p>

<blockquote>
  <p>… I really try to make my schedule safe for serendipity. I spend a lot of time going over old conversation summaries. A lot of the old ones are about ideas that ended in failure, the project didn’t work. But hey, you know what? That was five years ago, and now computers are faster, or some new information has come along, the world is different. So we’re able to reboot the project</p>
</blockquote>

<p>So we have two rather-famous-Richards and neuroscience superstar Ed Boyden giving similar advice: know the ins and outs of a few particular problems, the current bottlenecks and limitations. Then as you bump into novel ideas, analytical techniques, manufacturing, or technical procedures, you can quickly ask yourself if the new thing could possibly enable progress on one of your pet problems. I call a new process, material, technique, model, mathematical paradigm, or physical law which enables progress on a difficult technical problem a <strong><em>Hamming Enabler</em></strong>.</p>

<p>Hamming Enablers are interesting retrospectively and prospectively. Retrospectively, we can ask why powered flight was not invented in the 1600s, or we can ask what had changed around 1903 that suddenly made it tractable. Prospectively, we can ask what tech a given new development might Hamming-Enable (does that make sense?), or reverse the question and ask what Hamming Enablers we might require to reach a certain technological goal (the backward-chaining idea I mentioned earlier).</p>

<p>So, without further delay, let’s step through the list<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup></p>

<h2 id="computation-intelligence-and-coordination">
<a class="anchor" href="#computation-intelligence-and-coordination" aria-hidden="true"><span class="octicon octicon-link"></span></a>Computation, Intelligence, and Coordination</h2>

<h3 id="heterogenous-compute-and-non-von-neumann-architectures">
<a class="anchor" href="#heterogenous-compute-and-non-von-neumann-architectures" aria-hidden="true"><span class="octicon octicon-link"></span></a>Heterogenous Compute, and Non-Von-Neumann architectures</h3>

<p>Moore’s Law is slowing down, and every year chip-makers are doing their best to squeeze more performance out of semiconductor design. To the extent that they fail or fundamental physical limitations in the size of semiconductors set in, we’ll need to use other strategies to see continued progress in computing power.</p>

<p>The Apple M1 chip is a good example here: the M1 is what’s known as a System on a Chip (SoC). Instead of each component in the computer plugging into a motherboard, the whole thing is on one piece of silicon, minimising distance between components and allowing for optimisation of the unit as a whole.</p>

<p>At the extreme end of hardware specialisation we get Application Specific Integrated Circuits (ASICs). Here, we just hardcode the program we want to execute into the logic gates of the processor, sacrificing the flexibility of more general architectures for pure speed.</p>

<p><a href="https://mule.substack.com/p/heterogeneous-compute-the-paradigm">Heterogenous compute</a> captures the idea of combining ASICs into our devices (laptops, smartphones, self-driving cars, etc.) for some of the most common tasks, thus getting the speed and efficiency benefits of an ASIC while preserving the generality of the device. For example, the iPhone has a dedicated image-processing chip alongside its general processor, and we can imagine generalising this for almost any device that finds itself performing one or two computations far more often than any others.</p>

<p>An obvious area we’ll see something like this in is in AI-specific hardware. TPUs (tensor processing units) are already one attempt at this, but we can do better. If we think of computing as a process happening in a specific medium, with a specific architecture, then we can ask if there are other computational mediums, and other computational architectures that might be useful. Right now, the medium we use to compute is electronic - electrons in moving in transistors, and the architecture is essentially<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup> the Von Neumann Architecture.</p>

<h4 id="beyond-electronic-compute">
<a class="anchor" href="#beyond-electronic-compute" aria-hidden="true"><span class="octicon octicon-link"></span></a>Beyond Electronic Compute</h4>

<p>Moving electrons around has its limits. There’s resistance and heat dissipation to think about, as well as their mass and the amount of energy needed to move them at a given speed. Photons on the other hand… also have a bunch of problems as a computational medium (hence requiring progress in materials science), but they don’t have mass, so that’s a start!</p>

<p><img src="/blog/images/techno-optimism/drake_compute.jpeg" alt="Drake Meme"></p>

<p>Nonetheless, some concrete progress has been made, especially if (in keeping with the heterogenous compute theme above) you restrict the types of operations you want to perform. Modern deep learning requires a lot of matrix multiplication, and it seems like there’s been relatively more success using light to compute in this setting:</p>

<ul>
  <li>Researchers have shown dramatic <a href="https://arxiv.org/abs/2104.13467">efficiency improvements</a> in training neural networks using photons.</li>
  <li>A startup called <a href="https://lighton.ai/">LightOn AI</a> has developed an entire <a href="https://arxiv.org/abs/2012.06373">photonic processor</a>. This is cool because they used this processor to implement a non-standard algorithm for training neural nets called Direct Feedback Alignment, which touches another theme from later in the post. I’ll have more to say about going ‘beyond backprop’ in the AI section of the list, but noting how items on this list are synergistic and Hamming-Enable each other is like half the reason I’m so excited.</li>
</ul>

<h4 id="beyond-von-neumann-compute">
<a class="anchor" href="#beyond-von-neumann-compute" aria-hidden="true"><span class="octicon octicon-link"></span></a>Beyond Von Neumann Compute</h4>

<p>Our abstract model of computation comes from the Turing Machine. But we want a concrete implementation if we’re to do any actual computing (ain’t nobody got time for an infinitely long tape). John von Neumann gave us his eponymous architecture, and it’s pretty recognisable in just about any computing-device you’re likely to have. It consists of inputs (touchscreen, mouse, keyboard), a CPU which executes the instructions made by programs, external memory, which stores data and programs, and some outputs (screen, printer). Note that the CPU and memory are separated, meaning data needs to be transferred between the two. The <a href="https://www.wikiwand.com/en/Von_Neumann_architecture#/Design_limitations">von Neumann bottleneck</a> refers to the limitation imposed on the speed of computing because of the latency introduced by this data transfer. What’s worse is that while we’ve both sped up our CPUs and increased the density and capacity of our memory, the rate of data transfer has remained relatively stagnant, meaning the von Neumann bottleneck has gotten worse. We get around it with a bunch of tricks like RAM, caches, and multithreading, but as a limitation its baked into the way we build computers.</p>

<p>So what if we just <em>didn’t do that</em>? These are the so-called non-von Neumann architectures, and at their most basic they try to find a way to do ‘in-memory’ computing, so that the CPU doesn’t have to wait around for data to be shipped-in from memory. A subset of these go by the name ‘<a href="https://www.nature.com/articles/s41565-020-0647-z">neuromorphic compute</a>’ because of some (loose) analogies to biological neurons. This is also a form of heterogenous compute, and one of the main reasons to make a neuromorphic computer is to allow for more efficient use of artificial neural networks, which is a nice synergy to have if AI is going to be increasingly important!</p>

<p><img src="/blog/images/techno-optimism/vn_arch.png" alt="Von Neumann architecture"></p>

<h3 id="ai">
<a class="anchor" href="#ai" aria-hidden="true"><span class="octicon octicon-link"></span></a>AI</h3>

<p>Having a section like ‘AI’ in a list of things to be optimistic about is too broad, and not exactly a revelation to anyone likely to be reading this. Like all of the things on this list, the people working in this field tend to role their eyes at lists like these because they actually know enough about the day-to-day challenges of the work to know that something simple sounding like “use AlphaFold to enable the next generation of drug discovery” is sweeping <em>a lot</em> of practical tedium under the rug. This is probably true for everything on this list, so we might as well acknowledge it here.</p>

<p>So what, <em>specifically</em> is happening in AI right now that should give us optimism?</p>

<p>One is just a personal hunch, and that is that there really is <em>progress</em> in the field. I don’t have a legible description here, but AI right now feels alive and generative in a way which few fields do. Another personal hunch is that there are many specific techniques which are aimed at solving individual problems getting pushed to Arxiv daily, and no one has the time to pick the low-hanging fruit of combining them. By this I mean that for many of the specific problems someone could point to with AI, someone is publishing something to the Arxiv that addresses it. It might not solve it completely, or it comes with tradeoffs, but the turn-around times are impressive.</p>

<p>For example, let’s use the relative inefficiency and large computational overhead of using Transformers in all the super powerful GPT-X-esque language models. Models like these come under fire by AI critics, who cite the cost and environmental impact of using all those GPUs, or the amount of data needed to train the model, as problems. But then, in the span of just 6 months (from January to June of 2020) there were several different proposals addressing both these issues, including the <a href="https://arxiv.org/abs/2001.04451">Reformer</a>, the <a href="https://arxiv.org/abs/2009.14794">Performer</a>, the <a href="https://arxiv.org/abs/2006.04768">Linformer</a> and <a href="https://arxiv.org/abs/2006.16236">others with less catchy names</a>.</p>

<p>On one hand. I can imagine a sceptic saying something like “those are just incremental improvements pushed out to get citations”, but a) it’s absolutely awesome that the field moves fast enough that multiple serious solutions are posted so quickly to serious challenges, and b) the incentives of academia are not set up for researchers to refine those techniques and set them up for production-level AI, let alone combine disparate improvements across research labs and productionise the combination, making them seem more incremental than they really are. The times where this has happened (e.g. the pretty standard combination of ResNets + dropout + SGD + batchnorm for many computer vision tasks) has produced phenomenal results, and importantly, each of those techniques seems to work <em>synergistically</em> with the others. My gut feeling is that there are other unexplored, unrefined (to production-level, not academic research level) combinations just waiting to be plucked from the Arxiv!</p>

<p>Okay, enough “gut feelings” and “hunches”, let’s be concrete!</p>

<p>First, my one paragraph summary of how I see the state of AI right now:</p>

<p><em>Humans have “solved” many of the original challenges of the field (image recognition, text generation, game-playing), mostly using classique supervised deep learning. Big efforts will be made to continue adding parameters to Transformers to see when, if ever, this stops improving their performance. Current success is largely due to some brilliant architectural and training tricks, all mashed together with oodles of labelled data from the internet and lots of computing power. Transfer learning makes these pretrained models available to anyone and so now anyone can benefit from that one time outlay of compute to build more specialised models. Reinforcement learning remains more challenging, but things like <a href="https://youtu.be/_L3gNaAVjQ4?t=4213">MuZero look seriously promising</a>.</em></p>

<p>So what’s new:</p>

<p>Well self-supervised learning seems to be going through <a href="https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence">a bit of a renaissance</a>. A big sticking point in AI right now is the availability of labelled data from which to learn, and the ability to do common sense reasoning even on situations you haven’t specifically trained on. Self-supervised learning tries to address the former by learning something about the (statistical) structure of the data in general, and in doing so, possibly improve at the latter. A few new approaches have surfaced recently, often using the idea of “<a href="https://arxiv.org/abs/1807.03748">contrastive learning</a>” to setup the agent to try and predict unseen parts of the data, given the context of seen parts - no labels required! I think some scheme like this is one way we could build robust <a href="https://worldmodels.github.io/">world models</a> for our model-based RL agents, and I think good world models are the key to some of the “common-sense” reasoning some people bemoan AI for lacking.</p>

<p>Another thing I’m optimistic about is AI augmenting and enabling new physical possibilities. It seems many people currently think of ‘AI’ as either the thing that makes your Instagram feed eerily mirror your innermost thoughts, or something to do with making robot dogs walk around. Instead, what we should focus on is that we have a decade of experience training optimisers that are <em>extremely</em> good at traversing high-dimensional spaces, and now we get to choose whether that space is about which ad to serve you on YouTube, or about the tiny proportion of physical arrangements of molecules that generate a particular response in a petri-dish of cells.</p>

<p>AI for scientific discovery is an obvious Hamming Enabler. Right now, a group of researchers can discover new facts about physical materials just by exploring the latent space of a <a href="https://perssongroup.lbl.gov/papers/dagdelen-2019-word-embeddings.pdf">language model trained on the materials science literature</a>. More generally, we can think of doing reinforcement learning in unique state-action spaces<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">4</a></sup>. So instead of imagining an agent being able to choose how to move through a physical environment using familiar actions to those available to us as humans, we could imagine our state space as being the molecules present in a beaker, and which are bound to which and in what positions. The action space could be the set of known chemical reactions, or application of some catalyst, and the agent could have the objective of creating a molecule we specify before-hand, but don’t currently know how to synthesise.</p>

<p>Generative design also seems relevant to point out here. It’s a neat bonus of most models that once you’ve trained them to (e.g. in the case of AlphaFold) predict protein structure from the amino-acid sequence, you can probably invert them and do the reverse, or you can use the latent space that encodes all the knowledge to ask further hypothetical questions about protein structure. A lot was made about drug-discovery using AlphaFold, but I tend to think of it as the first steps towards AutoCAD for molecular machines (and believe me, proteins aren’t just ‘like’ molecular machines. <a href="https://www.youtube.com/watch?v=cwDRZGj2nnY">Proteins</a> <a href="https://www.youtube.com/watch?v=b_cp8MsnZFA">are</a> <a href="https://www.youtube.com/watch?v=wJyUtbn0O5Y">molecular</a> *<a href="https://www.cell.com/cell/fulltext/S0092-8674(21)00430-X?rss=yes#.YH7qgn0rnEY.twitter">machines!</a> [paywalled]). So predicting proteins accurately is certainly impressive and useful, but my guess is that there’s far more value to be extracted by some combination of an RL agent able to act with something like AlphaFold as its world-model. That being said, the state of AI+protein design is stupendously exciting - just look at Einstein.ai’s use of <a href="https://blog.einstein.ai/learning-from-evolution/">language models for protein design</a>!</p>

<p>More than this, I think the people trying to do something different from just scaling up Transformers have a chance of making a breakthrough. Self-supervised learning is part of this, but some even more fundamental shifts are afoot. I continue to think that Karl Friston’s Active Inference, and the related Free Energy Principle, will have important things to contribute to mainstream AI. Early signs of this are:</p>

<ul>
  <li>Active inference based models outperforming traditional ones in the non-stationary multi-armed bandit task (<a href="https://arxiv.org/abs/2101.08699">paper</a>).</li>
  <li>Active inference encompassing and extending traditional reinforcement learning (<a href="https://arxiv.org/abs/2002.12636">paper</a>)</li>
  <li>Active inference ideas making their way into publications by big, industry facing research labs like DeepMind (<a href="https://arxiv.org/abs/2009.01791">paper</a>)</li>
  <li>Predictive coding (key neuroscientific account of brain function, heavily studied by FEP/active inference crowd because of formal similarities) shown to approximate the backpropagation algorithm (key ingredient in training our current deep neural nets) (<a href="https://arxiv.org/abs/2006.04182">paper</a>)</li>
</ul>

<p>More things to be excited about:</p>

<ul>
  <li>I remain excited about neural net architectures that take advantage of the structure or symmetry of the data - <a href="https://arxiv.org/abs/1902.04615">gauge-equivariant neural nets</a>, graph neural nets, <a href="https://geometricdeeplearning.com/">geometric deep learning</a> - all seem full of possibility</li>
  <li>
<a href="https://arxiv.org/abs/1806.09055">Architecture search</a> as well as learning to create <a href="https://arxiv.org/abs/2101.07367">optimisers which learn to train themselves</a> point to a path where “end-to-end” ML means also learning an architecture and an optimiser that’s particularly suited to your task. Related: <a href="https://arxiv.org/abs/1803.03635">the lottery ticket hypothesis</a> and possibly using this to enable much smaller edge networks</li>
  <li>
<a href="https://arxiv.org/abs/2104.13386">Physical neural networks</a>. Heavily related to heterogenous compute above, but there’s even more awesome stuff in the mix which I think has barely been explored. I have an entire blog post in the works about these!</li>
  <li>
<a href="https://distill.pub/2020/selforg/">Neural cellular automata</a>. The extensions already created to this idea are crazy. See: <a href="https://avariengien.github.io/self-organized-control/">Towards Self Organised Control</a> and <a href="https://arxiv.org/abs/2103.08737">Growing 3D Artefacts and Functional Machines with Neural Cellular Automata</a>. As a heuristic model of complex system development, and a way of creating robust self-organising systems, I think this is a promising direction of research.</li>
</ul>

<h3 id="crypto">
<a class="anchor" href="#crypto" aria-hidden="true"><span class="octicon octicon-link"></span></a>Crypto</h3>

<blockquote>
  <p><em>and thus the transformation into tech-bro was complete</em></p>
</blockquote>

<p>Crypto gets a bad rap. For many it’s the perfect combination of the vitriol and tribalism of the internet, muddled up with the embarrassment, fear, and greed of personal finances. But there are some specifics about crypto that excite me, especially if we think of it as a general Hamming Enabler for a host of heretofore untried <a href="https://www.vitadao.com/">experiments</a> in social coordination, cooperation, fundraising, and governance.</p>

<p>As a warm up to the possibilities, let’s contemplate this tweet:</p>

<p><img src="/blog/images/techno-optimism/spak_tweet.png" alt="https://twitter.com/spakhm/status/1386933188652503040"></p>

<p>I think this matters because of 2 things: 1) permissionless innovation, and 2) fast feedback loops (bonus for the feedback in crypto usually being monetary, so the incentives are pretty real from the get-go).</p>

<p>Arguably one of the big reasons we had such big slowdowns in innovation <a href="https://wtfhappenedin1971.com">post-1970</a> is that we regulated away our ability to innovate. If you need millions of dollars in lobbyists, and years of filing paperwork to get your HyperLoop installed, it’s probably going to be really hard to iterate fast enough to make mistakes and learn from them, and you wouldn’t want to because delays and redesigns will be costly and subject to more paperwork<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote" rel="footnote">5</a></sup>. Compare that to the relatively unregulated software sector from 2000-2016, where (even if bad things have happened), it’s hard to deny that e.g. the ideas and implementation of companies like Uber and AirBnb are innovative approaches to solving their respective problems.</p>

<p>Crypto, if nothing else, has opened up another frontier for people to play around and try out new ideas. Specific coins may come and go, and scams will be inevitable (sort of like the early internet), but at the same time a core of dedicated, super-smart people with genuine morals and a desire to create something important will be working away like crazy in the background. Take a look at <a href="https://numer.ai/">Numerai</a> for an example of something which I would claim was Hamming-Enabled by the development of cryptocurrency. I also think that we’ll see the <a href="https://ethereum.org/en/dao/">DAO</a> concept continue to develop and mature, which might itself Hamming-Enable new ways of funding research and other public goods. Plus, there’s never been a better time to be a mechanism design researcher, because suddenly you can try out fancy things like <a href="https://www.radicalxchange.org/concepts/quadratic-funding/">Quadratic Funding</a>, at scale, in the wild, and learn from that.</p>

<p>More things to be excited about:</p>

<ul>
  <li>Ethereum scaling solutions (<a href="https://ethereum.org/en/developers/docs/scaling/layer-2-rollups/">optimistic and ZK-rollups</a>) + <a href="https://ethereum.org/en/eth2/shard-chains/">sharding</a> in the longer term look like they will work, and when they do I think of them as being Hamming Enablers for the entire Ethereum ecosystem</li>
  <li>Lots of individual things in the DeFi space. It’s a bit of a contrived example, but think about <a href="https://aave.com/flash-loans/">flashloans</a> for a second. The fact that suddenly anyone on earth can borrow hundreds of millions of dollars with zero collateral and no need for a credit check is <em>wild</em>. So far it’s mostly been used for arbitrage opportunities (and attacking/exploiting liquidity farms), but as Hamming-enablers go, if we’re just asking the question “what’s something that’s now possible that previously wasn’t?” this is one of those things. I think we’re all just waiting for someone smart to show us some new, powerful application that no-one else has thought of yet.</li>
</ul>

<h2 id="progress-institutions-and-politics">
<a class="anchor" href="#progress-institutions-and-politics" aria-hidden="true"><span class="octicon octicon-link"></span></a>Progress, Institutions, and Politics</h2>

<h3 id="progress-studies--techno-optimism">
<a class="anchor" href="#progress-studies--techno-optimism" aria-hidden="true"><span class="octicon octicon-link"></span></a>Progress Studies &amp; Techno-Optimism</h3>

<blockquote>
  <p>Yes, I’m optimistic about the optimists</p>
</blockquote>

<p>Stagnation - both technological and economic - is bad. Luckily, having identified the shape of the problem (or at least maybe <a href="https://wtfhappenedin1971.com/">the year it started?</a>), we can start to look for solutions. The “progress studies” crowd<sup id="fnref:6" role="doc-noteref"><a href="#fn:6" class="footnote" rel="footnote">6</a></sup> - a group of people determined to understand the causes of productivity stagnation and how we can return to or even exceed previous high levels of growth - is a great signpost to others that we should-and-do care about pushing society down a path of growth and technological development.</p>

<p>I think there’s a whole conversation to be had about the kinds of memes we distribute and the extent to which our media and our civilisational storytelling can be a driving force for progress. Personally I find reading the <a href="https://noahpinion.substack.com/p/techno-optimism-roundup">techno</a>-<a href="https://www.agglomerations.tech/cracks-in-the-great-stagnation/">optimists</a> to be infectiously optimism-inducing, and I think that’s a flywheel worth spinning up!</p>

<h3 id="parpa-new-science-focused-research-organisations-and-all-that">
<a class="anchor" href="#parpa-new-science-focused-research-organisations-and-all-that" aria-hidden="true"><span class="octicon octicon-link"></span></a>PARPA, New Science, Focused Research Organisations, and all that</h3>

<p><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3822691">Is scientific progress slowing down?</a> And if it is, how much of that is due to intrinsic factors (e.g. picking all the low-hanging fruit to be discovered) versus something about the <em>way</em> we do science? I am strongly in favour of diversifying our funding models and talent-selection-institutions, and that’s why I’m excited about proposals like <a href="https://benjaminreinhardt.com/parpa">Private DARPA</a> by Benjamin Reinhardt, or <a href="https://www.dayoneproject.org/post/focused-research-organizations-to-accelerate-science-technology-and-medicine">Focused Research Organisations</a> by Adam Marblestone and Samuel Rodriques, or Alexey Guzey’s <a href="https://newscience.org">New Science</a>. It’s also why I’m optimistic about crypto because, on the margin, having a different cohort of wealthy people with a higher than average predisposition towards techno-optimism, enabled by new mechanisms like DAOs and various yet-to-be-invented smart contracts, seems like it could enable a bunch of people to contribute towards R&amp;D who otherwise wouldn’t have!</p>

<h3 id="charter-cities">
<a class="anchor" href="#charter-cities" aria-hidden="true"><span class="octicon octicon-link"></span></a>Charter Cities</h3>

<p>The basic idea of a charter city is this: a bunch of people approach a nation-state and negotiate some contract to create a special jurisdiction somewhere in their country and build a city. The city builders get to experiment with best-practices in-governance, and can use the blank-slate to try encourage (i.e. set up innovative incentive structures) especially high rates of growth, entrepreneurship, sustainablility, or whatever the founders and the population care about. In exchange, maybe they funnel some percentage of the city’s taxes back to the nation state, leaving everyone better off than if there had been no charter city.</p>

<p>Again, in the spirit of letting a thousand flowers bloom, I think the <a href="https://www.chartercitiesinstitute.org/intro">charter city</a> space is exciting. This follows because, if you think that maybe we’re hindering our ability to build by regulatory-strangulation, having diversity of regulatory environments will allow for more experimentation.</p>

<p>Scott Alexander has been doing a great job of dissecting <a href="https://astralcodexten.substack.com/p/model-city-monday">various attempts at creating charter cities and things like them</a>, and also has a <a href="https://astralcodexten.substack.com/p/prospectus-on-prospera">detailed review</a> of the charter city, <em>Próspera</em>.</p>

<h3 id="mechanism-design--social-technologies">
<a class="anchor" href="#mechanism-design--social-technologies" aria-hidden="true"><span class="octicon octicon-link"></span></a>Mechanism Design &amp; Social Technologies</h3>

<p>I think two big Hamming-Enablers for meaningful mechanism design will be the combination of <em>usable</em> augmented/virtual reality devices (think e.g. a pair of glasses that could overlay everything you currently see on your iPhone onto the world in front of you, so no need to look down or stop what you’re doing) and the crypto stuff we’ve talked about earlier. The AR side helps us bring our digital incentive tools out into the physical world. The crypto side is useful for creating ecosystems with financial incentives and rules enforced by code.</p>

<p>I think that <a href="https://slatestarcodex.com/2014/07/30/meditations-on-moloch/">coordination problems</a> problems and <a href="https://equilibriabook.com/">inadequate equilibria</a> are at the root of much of what’s wrong in the world currently, and that, even though they’re amongst the hardest problems out there, on the margin it’s worth investing in technologies that mitigate them. If we’re going to become a ridiculously powerful civilisation, we’re going to need ways to coordinate and prevent e.g. AI-arms-races, or further nuclear-proliferation, or any race-to-the-bottom where <a href="https://www.nickbostrom.com/papers/vulnerable.pdf">‘the bottom’ = civilisational destruction</a>.</p>

<p>On a less existentially-critical note, designing better policy and incentive structures is worth thinking about generally. I remain a fan of Glen Weyl’s <a href="https://www.radicalxchange.org/">RadicalxChange</a> project, and his <a href="http://radicalmarkets.com/">book</a> with Eric Posner was the thing that convinced me that there could be solutions to these sticky coordination problems at all. On a related note, I’ve enjoyed reading Samo Burja’s analysis of the importance of <a href="https://samoburja.com/social-technology/">social technology</a> in creating and sustaining successful institutions.</p>

<h3 id="meaningness-and-meta-rationality">
<a class="anchor" href="#meaningness-and-meta-rationality" aria-hidden="true"><span class="octicon octicon-link"></span></a>Meaningness, and meta-rationality</h3>

<p>This last entry might seem out of place on a list that’s been primarily technology-focused, but if we are to <a href="https://youtu.be/_L3gNaAVjQ4?t=1831">increase our power over the universe</a>, we should invest a commensurate amount of energy in learning to use it wisely. I think the EAs and other longtermists are making a good start here, but something that’s made the most difference personally is David Chapman’s work at <a href="https://meaningness.com/">Meaningness</a>, <a href="https://vividness.live/">Vividness</a>, and on <a href="https://metarationality.com/">metarationality</a>.</p>

<p>It’s hard to say where to start because his writing is this sprawling <em>nebulous</em> living document, but <a href="https://metarationality.com/stem-fluidity-bridge">here</a>, <a href="https://vividness.live/developing-ethical-social-and-cognitive-competence">here</a>, and <a href="https://meaningness.com/an-appetizer-purpose">here</a> are pretty solid jumping off points. Chapman gently builds up a framework for dealing with the dimensions of what he calls “meaningness”. The tagline for the site is “<em>Better ways of thinking, feeling, and acting—around problems of meaning and meaninglessness; self and society; ethics, purpose, and value.</em>” and it’s pretty accurate. It’s hard to try and vouch for this particular set of ideas about meaning without sounding like every other religion/cult/self-help-guru trying to advocate for <em>their favourite</em> <u>One True Solution</u> to Your Life’s Problems. Thankfully, <em>Meaningness</em> isn’t meant to be a self-contained personal philosophy that’s fully general. Actually, that’s kind of one of Chapman’s points - that no system can ever be final and all-encompassing. It’s the thing I’ve recommended most often to friends when they’re having problems that <em>can’t</em> be solved with a debugger or a trick for doing a weird integral.</p>

<h2 id="conclusion">
<a class="anchor" href="#conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion</h2>

<p>What have I left out here? What else is there to be excited about? Obviously this list is far from exhaustive and is more ‘personal opinion’ than me saying “objectively these things are <em>the best”</em>.</p>

<p>The list continues in part 2, where I talk about everything I’m excited about in <strong>Materials,  Molecules, and Manufacturing</strong> as well as <strong>Biology, Medicine, and Biotechnology</strong>. If there’s anything you think I should check out in those areas before then, my <a href="https://twitter.com/jnearestn">twitter DMs</a> are open!</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Ed Boyden’s lab birthed both optogenetics and expansion microscopy, which have both been gigantic Hamming-Enablers in neuroscience research <a href="#fnref:1" class="reversefootnote" role="doc-backlink">↩</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Initially, I wanted to work through the Hamming Enablers for each thing on my list - both in terms of what is now enabling that thing, and what it might be a Hamming Enabler of, but honestly I just don’t know enough about many of the ideas to reliably do that, so instead I’ll leave some of it as an exercise for the reader. I think the list has value in-and-of itself so I’ll include it in its entirety <a href="#fnref:2" class="reversefootnote" role="doc-backlink">↩</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>Yes yes, Harvard architecture. But Non-Von Neumann sounds cooler than Non-Harvard <a href="#fnref:3" class="reversefootnote" role="doc-backlink">↩</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>In RL, the state space is all the possible states the agent could be in. Typically this would be positions in a gridworld. The action-space is the space of available actions e.g. at every timestep pick one of [walk left, walk forward, walk backward, walk right, stay still]. My argument is that people tend to forget that state/action spaces can be a whole lot more abstract than that, and that enables a lot of exciting applications <a href="#fnref:4" class="reversefootnote" role="doc-backlink">↩</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>maybe the thing I admire most about Elon Musk is the fact that he actually tried to innovate in a bunch of these areas that are prototypically stymied under regulatory nonsense (spacetravel, energy, full-self-driving) <a href="#fnref:5" class="reversefootnote" role="doc-backlink">↩</a></p>
    </li>
    <li id="fn:6" role="doc-endnote">
      <p>See for example the excellent https://rootsofprogress.org/ <a href="#fnref:6" class="reversefootnote" role="doc-backlink">↩</a></p>
    </li>
  </ol>
</div>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="jaredtumiel/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/2021/08/06/techno-optimism1.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>To live is to risk it all; otherwise you&#39;re just an inert chunk of randomly assembled molecules drifting wherever the universe blows you...</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/jaredtumiel" target="_blank" title="jaredtumiel"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/jnearestn" target="_blank" title="jnearestn"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
