{
  
    
        "post0": {
            "title": "In What Sense is Matter 'Programmable'?",
            "content": "David Deutsch, described aptly by Tyler Cowen as a kind of “philosopher of maximal freedom” famously points out that any state of the universe that is not explicitly prohibited by the laws of physics, is therefore realisable by some set of physical transformations using those laws. The gap between our current state and that unrealised-but-possible future state is a gap in our knowledge. In this way, Deutsch elevates ‘knowledge’ to a kind of fundamental force in the universe. Our ability to create useful explanations about the physical world increases our knowledge, and by increasing our knowledge we are able to access more possible states. In a Deutschian sense, the only reason humans can’t currently live for hundreds of years isn’t because it’s prohibited by the laws of thermodynamics (it’s not!), it’s because we lack the requisite knowledge to apply the correct physical transformations to matter that would prolong our lifespans. . Deutsch’s distinction between discovering and describing the laws of the universe (the job of theoretical physicists as currently understood), and enumerating the possible realities contained within (or allowed by) those laws, hints at a broader conception of physics: the physics of the possible. By simply asking what constraints there are on a system, or in what ways we can not violate those constraints, we can uncover the true richness contained therein. This post is an exploration of the constraints of physical matter, and in what ways it is ‘programmable’. . An analogy to get us started: . By the mid 1930s, Alan Turing and Alonzo Church had formalised every detail of computation as we now understand it. The mathematics of the Universal Turing Machine (UTM) was complete - as grand unified theories go, it was a knockout. We can imagine the Turing Machine as a kind of ‘universe’ - let’s call it the UTM-verse. Like our own universe, the UTM-verse is complete with a set of laws. Want to go faster than light in our universe? Too bad - against the law. Want to write a programme that decides if another program halts in the UTM-verse, too bad! Against. The. Law! But even though we had the exact laws pinned down since the ’30s, it took another 76 years for somebody to create Tinder and instantiate it on a Turing Machine1. Why the delay? Did we need a revolution in computer science between Turing and Tinder in order for it to be born? Clearly not! Tinder was always theoretically possible within the known laws of computation but, in a Deutschian sense, it required an act of creativity to conceive of the set of transformations within those known laws that were required to instantiate it. . So now that we appreciate that knowing the laws that govern a system doesn’t tell us about all the cool things we can do with those laws, let us consider the ways in which matter might similarly be ‘programmable’. Here I mean programmable in two senses: . ‘Programmable’ as an analogy to the above spiel about computer programs - i.e. as a system which, if we knew its fundamental laws, would still contain interesting phenomena if we had the creativity to use those laws in novel ways | ‘Programmable’ as in literally we could give ‘instructions’ to matter, and like a Universal Turing Machine, it would be able to interpret or follow those instructions, carrying out either literal computation, or just reorganising itself according to some ‘program’ | . The Obvious . . Trivially, every Universal Turing Machine must be instantiated in the matter of our physical universe if it is to do any computing. The original Turing Machine was proposed as a kind of Platonic mathematical entity, consisting of an infinitely long tape with symbols inscribed at interval which instructed the machine on what action to take next. Unfortunately, big as the universe may be, infinitely long tapes aren’t practical. Thankfully, we are lucky enough to live in a universe where we can make perfectly good approximations to the UTM - no tape required! . So the mathematics governing computers and computer programming is realisable within our universe, which means that the atoms that comprise whatever system we use to emulate the UTM are in some sense ‘programmable’ matter. Each electron in the transistors of your computer is obeying simple laws of physics, and the movement of those electrons alters its physical properties so that it acts like a switch which is in one of two binary states, and from that simple binary switch you can build little logic circuits that compute ‘AND’ or ‘XOR’ or ‘NAND’, or any combination thereof. And, somewhat surprisingly, all of those, when strung together, is enough to create all of the approximate Turing Machines you use and love. So physical matter is programmable. Neat! . As it happens, a lot of things are Turing-complete (able to simulate any other Turing Machine). Some are obvious (your laptop, smartphone), but many are less so: Microsoft Powerpoint is Turing complete, meaning you could (albeit inefficiently) do any computation in Powerpoint, including build the Apple OS! Cellular automata are also Turing complete, as is Factorio! From a physics point of view, we know that we can encode a Turing Machine in a 4-dimensional manifold, but also that computing certain facts about that manifold are then undecidable by that Turing machine! There are also interesting properties about the computational power of fluids (i.e. can the flow of water ‘compute’ something in a meaningful way?), and this has implications for long-unsolved questions about the Navier-Stokes equations! . The Quantum Obvious . . side note: I propose quantum computers are our most gorgeous-looking technology and we should celebrate this more . Quantum computers are also going to have to run in our physical universe! And so far, besides a few algorithms, the thing they might be most useful for is simulating the behaviour of quantum systems. Actually, if I’m careful not to just gloss over this, this feels really surprising. Try to seriously internalise for the moment that reality really is quantum mechanical. Not just abstractly know it’s true in textbooks, but like everything you see is some excitation of a quantum field. It feels pretty weird to think that you can take some of those excitations, couple them together, make some of the excitations (e.g. a photon or an electron) behave as ‘qubits’ which have a state which can be used to store computational information (e.g. the ‘Up’ or ‘Down’ spin states of the electron), and then you can use that computational state to build a simulation… of excitations… in a quantum field … like the spin of an electron… or the phase of a photon… . Aaaanyway… . Quantum Computing . It’s important to acknowledge that quantum computers aren’t more general than classic computers, but for certain things, they’re remarkably more efficient! So everything you can do with a quantum computer, you can simulate in a classical computer, given enough time/memory (what did you think the ‘Universal’ in ‘Universal Turing Machine’ was for?). . . this lovely diagram is from this Simon&#39;s Foundation report . Digging into the strange hall of mirrors situation of reality simulating reality that is quantum computing seems a worthwhile diversion right now if we are to dig into the question about programmable matter. So let’s do a whirlwind tour of quantum computing so that we can point out some intriguing points: . A quantum system has a number of ‘base’ states. Let’s use the spin of an electron, which can be either ‘spin-up’ or ‘spin-down’. Now that’s a nice two-state system, rather like the on-off ‘bit’ which we’d use in normal computing. . Let’s represent the spin-up state as the vector (10)​ begin{pmatrix} 1 0 end{pmatrix}​(10​)​ and the spin-down state as (01) begin{pmatrix} 0 1 end{pmatrix}(01​) If we call the whole quantum state $| psi rangle$​​​​​​​​​​, then we can2 represent that state as a linear combination of these two base states (a superposition, if we’re feeling cool): . ∣ψ⟩=α(10)+β(01)| psi rangle = alpha begin{pmatrix} 1 0 end{pmatrix} + beta begin{pmatrix} 0 1 end{pmatrix}∣ψ⟩=α(10​)+β(01​) . where $ alpha$​​ and $ beta$​​​​ are just coefficients telling us ‘how much’ of the ‘up’ or ‘down’ states we want in our total state. Now earlier we said we built up our remarkably general Universal Turing Machine with just combinations of ‘logic gates’ - things like the ‘AND’ gate, which returns ‘1’ if both its inputs are ‘1’, and ‘0’ in all other cases . . Turns out we can represent these logic gates as matrices. Let’s look at the ‘NOT’ gate - the ‘NOT’ operation just flips a zero to a one and vice versa. So we want NOT(‘spin-up) to equal ‘spin down’. Let’s call the operator doing this $X$​​​. We want $X$​​​ acting on (10) begin{pmatrix} 1 0 end{pmatrix}(10​) to give (01) begin{pmatrix} 0 1 end{pmatrix}(01​) The matrix which achieves this is . X=(0110)X = begin{pmatrix} 0 &amp; 1 1 &amp; 0 end{pmatrix}X=(01​10​) . and we can verify with normal matrix multiplication that: . (0110)(10)=(01) begin{pmatrix} 0 &amp; 1 1 &amp; 0 end{pmatrix} begin{pmatrix} 1 0 end{pmatrix} = begin{pmatrix} 0 1 end{pmatrix}(01​10​)(10​)=(01​) . But shouldn’t it be really interesting and weird to us that we can make matter itself ‘act’ like the matrix (0110)? begin{pmatrix} 0 &amp; 1 1 &amp; 0 end{pmatrix}?(01​10​)? (If that one doesn’t impress you then imagine a more complicated set of operations on qubits until you’re sufficiently impressed). I think some would say I have this exactly backwards and that matter is just doing its thing, and we’re finding ways in which that is approximately like the matrix X=(0110)X = begin{pmatrix} 0 &amp; 1 1 &amp; 0 end{pmatrix}X=(01​10​) . Putting that aside, it’s still intriguing to think that we have this mathematical formalism that describes quantum mechanics, and we can use quantum reality to ‘act out’ computations of that mathematical formalism. It’s apparently still unknown whether every possible physical system can be simulated in a quantum computer. David Deutsch certainly seems to think so3: . I had thought for a while that the quantum theory of computation is the whole of physics. The reason why it seemed reasonable to think that was that a universal quantum computer can simulate any other finite physical object with arbitrary accuracy, and that means that the set of all possible motions, which is computations, of a universal computer, corresponds to the set of all possible motions of anything. There is a certain sense in which studying the universal quantum computer is the same thing as studying every other physical object. It contains all possible motions of all possible physical objects within its own possible diversity. . Now as it turns out, there are many different ways we can build physical versions of our quantum computers. But in each, we try to set up some special circumstances where the annoying noise of the larger physical world doesn’t disturb our delicate quantum state so that we can use the quantum properties of matter to do computations like those above. This ability to change the informational content of matter sure feels like ‘programming’ matter to me. . Interested in quantum computing? You can’t do better than this intro by actual expert Michael Nielsen at quantum country . Synthetic Biology and ‘Active’ Matter . Breaking from the abstract world of computable functions for a bit, let’s look at biology - nothing’s ever been complicated there, right? . Going back to the analogy we started this post with - the space of all possible computer programs enabled by the laws of computation - what about the space of all possible organisms? This ‘space’ is interesting because there’s another actor in play - evolution by natural selection. Whereas the space of possible physical systems is something we “anthropic-principle” our way into, and the space of computer programs is something we as humans have been steadily exploring through acts of software creativity, the space of possible designs for biological creatures has been steadily explored by evolution for the last few billion years. Clearly the principles by which ‘eyes’ might work were not just possible within the laws of physics, but they’re possible within the narrower scope of the rules of biology and evolution. One of our species’ goals should be to explore more of the landscape of possible organisms! . Why speak of biological matter as ‘progammable’? . Cells can receive inputs, make calculations based on them, and output signals based on those calculations. Seems like a pretty decent computational system to me. This is true whether we’re thinking of neurons, or more general cells we don’t readily associate with computation. Synthetic biology is concerned with the ways in which we can intervene in a cell (or network of cells, or some other scale of the biological system) and shape the trajectory of the intricate cellular machinery to achieve a desired function or output. . A simple example of using biology to achieve ‘programmable’ matter is using genetic engineering to insert the gene for insulin into a bacterial cell. That gene acts as a template which can be transcribed into the insulin peptide, which we can purify and use to treat insulin-dependent diabetes. That insulin-secreting bacterial cell feels a lot like the kind of thing I want to call ‘programmable matter’: a little slice of reality we can direct and control - reconfigurable matter with custom functions! . Enhancing our ability to program and control biological matter is an interesting avenue because biological systems generally have a few other interesting properties: . Homeostasis - despite the dynamical flux of the world, biological systems tend to maintain many of their parameters within small ranges, despite perturbations. A laptop running your bootlegged copy of Sims 2 is fragile and static - delete one of the key lines of code and Sims won’t even open. Comparatively, the fidelity of DNA polymerase has an error rate of ~1 error per 100 000 nucleotides - meaning that per replicating diploid human cell (~6 billion base nucleotide pairs) there would be something like 120 000 errors. Clearly that isn’t the case, and the reason is because of DNA error correction and repair. The living cell has mechanisms to bring it back to the ‘set-point’ (in this case, the ‘correct’ genome for that organism). Living organisms tend to act, on themselves or their environment, in such a way that their key parameters are kept within viable ranges, whereas inert matter is subject purely to environmental degradation. | Autopoiesis - which refers to a system’s capability to reproduce itself by creating its own components - is an especially intriguing ability for a programmable system to have. Biology is the story of self-replicating molecular machines and the control systems they build. Tapping into this ability unlocks novel regenerative, replicative matter. It’s also terrifying if either evolution or humans program these replicators for harmful purposes. | Self-organisation - a single cell not only has all the computational abilities we’ve mentioned already, and the ability to execute almost arbitrary (DNA) code, but the cell can self-organise into functional forms of striking complexity, which is again, robust to perturbation. Think about trying to write the computer program that would generate a pair of lungs. You need to pave kilometers of tubing with cells, ensuring that there’s never a gap of more than 2 micro-metres between the airway and the capillary meant to ferry oxygen from it. And you need to do all of that in a non-static environment, responding to the movements of walking, breathing, growing. Programmable matter that can self-assemble intricate structures at both the molecular- and macro-level is a wild technology to even conceive of. The fact that it’s present and working in you right now is crazy! | . So cells and living systems generally have these properties, in addition to being able to execute instructions we give them. Want two more reasons to find cellular computation exciting? Fine! 1) Biological computation is extremely efficient - as in several orders of magnitude more efficient than the best supercomputers. And 2) biological learning rules significantly outperform those used in artificial intelligence right now (another reason I’m so optimistic about architecture search and evolved AI-optimisers!) The synergistic possibilities of all this give us good reason to think the 2020s will be the decade of synthetic biology! . What aspects of biology are ‘programmable’? . Some readers may have noticed that I casually failed to distinguish between two very different ways of programming biological matter: . We can imagine the DNA of the cell as providing the instruction set for the cell, and by editing the DNA, we ‘program’ novel functions and outputs into the cell . | We can send cellular signals by binding molecules to membrane receptors, the intracellular machinery of the cell can process this signal, and various outputs - in the form of up- or down-regulation, signal propagation, synthetic activity, etc. - can occur . | But it’s worth lingering on the various ways we can ‘program’ biological matter, then, because each may be useful, and they’re just really cool. . Programming by DNA editing . Firstly, DNA and genetics seems more like a lookup table than a programming language. You specify a string ‘GTG/CAC/CTG/ACT/CCT/GAG’ and that gives you the sequence of amino acids ‘Val/His/Leu/Thr/Pro/Glu’, and that’s the first 6 amino acids in the beta chain of human haemoglobin. There’s also lots of secondary features in this ‘language’ like reading frames and post-translational and post-transcriptional processing, and which genes are available for translation at a given time, and how translation is promoted or inhibited. But the basic idea of ‘inject’ new code and use the molecular machines to assemble it isn’t far off. . Tools like CRISPR give us this kind of ability to edit the genome, but more excitingly, open the path to novel protein design (tools like AlphaFold will be crucial here, but also see Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences and Deep neural language modeling enables functional protein generation across families for some incredible ideas that aren’t as famous as AlphaFold!) . Programming by epigenome editing . One problem with editing the genome directly is that cells generally don’t like it when you cause breakages in their DNA. So instead of trying to remove a problematic sequence, why not just suppress it so that it’s never expressed? As it happens, cells already possess machinery that can inactivate genes like this - and these epigenetic modifications provide a nice platform for programming the cell. Enter a recent CRISPR modification called ‘CRISPRoff’ (yes, there’s also a CRISPRon) which uses the sequence-targeting ability of CRISPR to direct molecular machinery that can methylate (and thereby inactivate) almost any part of the genome. This is a big deal because the difference between your hepatic cells and your neurons are largely differences in which parts of their genomes are expressed at any given time, and so the ability to selectively turn expression on or off is a potential Hamming-Enabler for fine-grained control of complex multicellular-morphology (see later in this post). . Programming by cell signalling . At the cellular level, we can bind all kinds of ligands to cellular receptors to set off any of the signalling cascades that regulate and control the cell. Achieving a high degree of control of these complex pathways would be a key milestone in medicine and longevity. This is nicely addressed in ‘Morphogenesis as Bayesian inference: A variational approach to pattern formation and control in complex biological systems’: . most problems of biomedicine – repair of birth defects, regeneration of traumatic injury, tumor reprogramming, etc. – could be addressed if prediction and control could be gained over the processes by which cells implement dynamic pattern homeostasis. . Indeed, a tantalising possibility, realisable by ‘programming’ biological circuits, would be a new type of drug. A drug that isn’t a single molecule with a single pathway or target, but that is itself a kind of ‘programme’, capable of reacting to the state of the cell it’s acting on and implementing different functions depending on that cellular state. I got this idea from Arye Lipman on his Substack The Last Great Mystery, where he calls therapeutics like this ‘logical medicine’. If we start thinking of disorders like cancer (or even aging generally) as derangements of the complex dynamical systems implemented in cellular regulatory networks, then being able to recognise, react to, and correct these derangements would be a sigificant step towards treating these diseases. . Programming with bioelectricity . . This gorgeous graphic by Ben Oldroyd for the Levin Lab . Cellular decision making is clearly reliant on more than just the cell’s genome (after all, every cell in your body has the same genome). Even if you account for different patterns of gene-expression between tissue types, we’re still left with unexplained fidelity in cellular morphological coordination. Enter biolelectricity! Turns out that simple physical variables like the charge-polarisation of cells can control wide-aspects of their morphology, and coordinate cells to adaptively achieve complex macro-scale objectives (like building an eye, or coordinating to make sure the right nerve cells make their way to that eye so that it’s usable). Oh, and there is increasingly awesome work by Michael Levin and colleagues that shows that if we intelligently intervene in these bioelectric circuits, we can alter key aspects of cell differentiation and proliferation. . Programming by training cell networks . . Max Hodak on Twitter . I like the thrust of this tweet - given all of the properties of living systems we’ve already mentioned, this seems like a useful experiment to perform. As far as I can tell, if we can think of a clever way to encode ImageNet and pass it to a network of cells, and if we could read the output, then training can proceed by either something akin to the method in Deep physical neural networks enabled by a backpropagation algorithm for arbitrary physical systems. Or, if we take the predictive processing perspective, maybe we can use what we know about the neurobiology of prediction-error signalling to train our ‘network’. Programming a piece of ‘predictive-matter’ like this could be really useful to neuroscientists trying to study these networks, and maybe to AI-researchers looking to learn something from biological intelligence. . Programming complex morphology - the neural cellular automata perspective . We can also think of what we can achieve if we leverage the three distinct properties of living matter (homeostasis, autopoiesis, self-organisation) in our programmed cells. What complex morphologies are we able to create, and what functions can we realise? One frustrating possibility might be that evolved circuits are too complex for humans to intelligently engineer (and maybe this is a cryptographic defence mechanism). So does that mean the project of synthetic biology is doomed? I don’t think so. . Back in the Ye Olde Days of Good Old Fashioned AI, we thought that hand engineering features and encoding huge knowledge-bases was the key to intelligence. Nowadays, we’ve seen the power of just black-boxing the system and using a powerful optimiser to learn whatever complex function we desire. No one knows how to write explicit rules to differentiate Chihuahuas from muffins, but if we avoid explicit rules and just train some parameters in a neural net, we do just fine! . . Andrej Karpathy extended this idea to coin the term ‘Software 2.0’, wherein he proposed a shift in how we create complex computer programs. Instead of explicitly programming each line of our app, we would specify an underlying architecture (a neural net), and provide it with some data which shapes its behaviour towards some desired functionality. I think we’ve seen early pieces of ‘software 2.0’ in some of the GPT-3 and OpenAI Codex demos. . So, if it does turn out that biology is too complex to ‘programme’ in the way we’re used to (the software 1.0/hand-engineered way), might we make progress with a kind of ‘Synthetic Biology 2.0’? . I first had a real ‘wow’ moment and began to think something like this may be possible after I saw the work on ‘Neural Cellular Automata’. Think about a standard cellular automaton, which has defined rules for how to update the grid, given its current state. In neural CAs, we learn the update rule, but more importantly, we learn a complex cellular ‘state’, which is analogous to the complicated cellular signalling cascades we’re imagining may be too complicated for humans to programme with directly. As the authors put it in ‘Growing Neural Cellular Automata’: . Hidden channels don’t have a predefined meaning, and it’s up to the update rule to decide what to use them for. They can be interpreted as concentrations of some chemicals, electric potentials or some other signaling mechanism that are used by cells to orchestrate the growth. In terms of our biological analogy - all our cells share the same genome (update rule) and are only differentiated by the information encoded the chemical signalling they receive, emit, and store internally (their state vectors). . Obviously, this is made much easier by not actually having to use real cells here, but I find the approach instructive. Don’t fuss around trying to understand all those internal pathways, just optimise the high-level objective4. I have spent some time thinking about ways that the ideas in Deep physical neural networks enabled by a backpropagation algorithm for arbitrary physical systems could be used to actually implement this kind of ‘black-boxing’ in cells, but so far haven’t made progress. Any comments with ideas here or links to work that might enable this kind of thing would be massively appreciated! . Aside 1: Obeying equations versus modelling equations . Lying just beneath the surface here is a somewhat intriguing thread to examine, which I’ll do so briefly. There’s a subtle distinction between the equations a system obeys at a fundamental level, and the equations a system can be made to model. In the quantum mechanical case, the quantum processes are described by the Schrodinger equation as their ‘master’ equation. But we can configure reality so that we can make that system imitate the matrices described above. Similarly, whatever equations are governing our biological system (presumably, ultimately, the Schrodinger equation), some arrangement of that system can be made to implement Bayesian inference. I think the authors of the Morphogenesis as Bayesian Inference paper implicitly say something like this, for example here: . To describe the dynamics of an ensemble of information processing agents (as in cells, for example) as a process of Bayesian belief updating, we need to relate the stochastic differential equations governing Newtonian motion and biochemical activity to the probabilistic quantities above. This is fairly straightforward to do, if we associate biophysical states with the parameters of a probability density – and ensure their dynamics perform a gradient flow on a quantity called variational free energy. Variational free energy is a quantity in Bayesian statistics that, when minimized, ensures the parameterized density converges to the posterior belief . You didn’t think I would write a blog post without mentioning the Free Energy Principle somewhere, did you? . Aside 2: The space of possibilities within biology . We asked at the start of this section what the space of biological organisms looks like, and what it contains. I can’t resist mentioning that this space isn’t static, and with synthetic biology we can actually increase the dimensions of the space. For example, the ‘space’ of all possible DNA sequences has as a fundamental constraint that those sequences must be made up of only four different nucleotides (ACTG). But there are efforts to introduce novel nucleotides into organisms, which would enable us to create protein sequences currently unreachable in our ‘little’ ACTG-world! Oh, also, some people recently effectively doubled the size of this space. . As we already mentioned, the ‘space’ of possible organisms has so far been explored by evolution, and we have a gorgeous, mesmerising variety of molecular machines and creature morphologies because of it. We should explore more of this possibility space - we should find out if we can find molecular machines that target viruses specifically (naming all of them after Harry Potter characters, obviously!), we should find organisms that solve our problems with microplastics, and bacteria that devour oil-spills. It’s time to build … a scalable pipeline for designing reconfigurable organisms! . Aside 3: Universal computation in biology . An interesting side-note that complements our discussion above about universal computers: there’s some debate about which systems in biology are actually Turing-complete. The thinking had been that gene-regulatory networks or cellular signalling cascades could be good candidates because they can be modelled as dynamical systems (i.e. systems of differential equations), and there were some proofs that some systems of differential equations can simulate our Universal Turing Machine. But it turns out that the kinds of differential equations that can simulate Turing Machines suffer from a kind of ‘instability’ that renders them quite possibly unrealisable in physical systems. One interesting proposal uses Lambda calculus and RNA to to construct a hypothetical biologically-plausible universal computer. . It’s interesting to speculate on how this meshes with the ‘RNA-world’ hypothesis that attempts to account for the origin of life. . Physical neural networks and The Manifold Hypothesis . Whew, that was a lot of biology. Let’s take a break by considering for a moment the effectiveness of deep neural networks and the ways in which physical systems can implement them. . Why Does Deep Learning Work? . So asks Lin, Tegmark, and Rolnick in Why does deep and cheap learning work so well?. The point they make is that the effectiveness of deep neural nets, which is often ascribed to their ability to approximate any arbitrary function, may be due also in part to physics. Given that “.. the set of possible functions is exponentially larger than the set of practically possible networks”, and that there are something like $256^{1 000 000}$ possible 1-megapixel images (for comparison, there are ‘only’ $10^{78}$​​​​​​ atoms in the universe), how come neural networks so reliably find functions which do indeed find the tiny fraction of these images which represent cats? . Their answer revolves around the same few principles that seem to make physics ‘simple’ (in terms of having relatively few parameters) - symmetry, locality, low-polynomial order. The laws of physics prune down that giant set of $256^{1000000}$​​ images into a small subset that are actually physical - or likely to be so. They also show various efficiency gains over ‘shallow’ networks that come about because the processes that ‘generate’ natural data tend to be hierarchical. . So this section is less about programming matter and more about asking why a particular type of programming (the optimisation of these deep nets) works so well. But can we connect this all up to actually program matter? . Physical neural networks . This is one implication of the ideas in Deep physical neural networks enabled by a backpropagation algorithm for arbitrary physical systems. . . From Deep physical neural networks enabled by a backpropagation algorithm for arbitrary physical systems . The basic idea is that we can ‘encode’ some input into a physical system, like a metal sheet, as a set of vibrations. We can also encode the parameters of our neural net as another set of vibrations which can constructively or destructively interfere with our input vibrations. We can then ‘read’ the output of the ‘network’ as e.g. the wavepattern of vibrations attained after the two sets of vibrations have intermingled. The network is trained by comparing the output of the real system to that predicted by a physics simulator for the system, and then the ‘parameter’ vibrations are adjusted accordingly until the desired output of vibrations is created. . Personally, I find this (and other approaches to using nature to instantiate neural nets) a very satisfying way to ‘programme’ matter! . Drexlerian Nanotech and Von Neumann’s Universal Constructor . . We had our first glance at programmable molecular machines in the ‘biology’ section of this post. And as the saying goes “anything worth doing with with Van Der Waal’s forces in organic chemistry is worth recapitulating in a diamondoid substance with covalent bonds”. Well, I’m not sure if that’s how it goes, but I could imagine J Storrs Hall’s birthday cards say something like that. . The goal of nanotechnology - the kind envisioned by Feynman in 1959 and theoretically developed by Eric Drexler in the late 20th century - is to have atomically precise control of matter. So precise in-fact, that we would be able to speak of a new phase of matter - the machine phase: . ..it would be a natural goal to be able to put every atom in a selected place (where it would serve as part of some active or structural component) with no extra molecules on the loose to jam the works. Such a system would not be a liquid or gas, as no molecules would move randomly, nor would it be a solid, in which molecules are fixed in place. Instead this new machine-phase matter would exhibit the molecular movement seen today only in liquids and gases as well as the mechanical strength typically associated with solids. Its volume would be filled with active machinery. . The capabilities of truly mature nanotech are astounding. In my favourite book of 2020, Where is My Flying Car?, the author estimates that we could recreate, from scratch “every single building, factory, highway, railroad, bridge, airplane, train, automobile, truck, and ship” in the entire United States …in a single week!. That’s the sheer power and capacity of systems whose native operating frequency is about a million Hertz! . Capabilities of mature nanotechnology . Actually, since the figures truly are astounding, I’ll rattle some off. I’m getting these from pages 428-432 of Drexler’s Nanosystems - Molecular Machinery, Manufacturing, and Computation: . Atomic precision - construct objects with features of ~0.3 nanometres in length, or 100 million distinct atomic features in a volume of 100 cubic-nanometres | Diamond-stiffness and strength (~55 times the tensile strength to density ratio of steel) | Directly convert between electric and mechanical power (and vice-versa) at a power density of ~$10^{15} text{W}/ text{m}^3$​​​, and between mechanical and chemical energy at a power density of ~$2 times10^9 text{W}/ text{m}^3$​​​ This is enough power density to put a 1000-horsepower engine inside a 1 millimeter cube | . | Use the ability to directly thermalise chemical potential energy to store ~$4 times10^7 text{J}/ text{kg}$​ | Design computational systems with CPU speeds of ~$10^9$​​ instructions per second, storing ~$10^{25} text{bits}/ text{m}^3$​ | . Nanotechnology and Universal Constructors . John von Neumann pre-empted the discovery of DNA by asking himself how self-replication was possible and consistent with the laws of physics. He realised (I’m paraphrasing David Deutsch from here) that you needed to specify instructions for assembling the system - that you couldn’t simply “copy-paste” the whole thing. From there, and knowing what we do about the universality of another machine that follows instructions on a tape (the Turing Machine), it’s natural to ask whether a universal constructor exists. Is there an arrangement of atoms such that that arrangement can reproduce all other arrangements? . Surely the ability to rearrange matter at will would constitute ‘programmable’ matter in the sense we’ve been investigating here? . Of course, now I should say something about the ‘programmable’ part. . Programming with atoms . You saw the title of Drexler’s book earlier, right? Nanosystems - Molecular Machinery, Manufacturing, and Computation. In it, Drexler sketches plans for building nanomechanical computers (as opposed to the familiar electronic computers we use for most things). Nanomechanical computers don’t use changing voltages in semi-conductors to represent zeros and ones, but instead represent them using the displacement of tiny rods into specific locations. . . Visualise Babbage &amp; Lovelace&#39;s mechanical computer, just a few billion times smaller . So if we could build and control systems in the machine phase we’d have a crazy amount of power over physical matter. We’d be able to separate, store, and control vast swathes of the material world! What could go wrong! . Exotic phases and weird physics . Now let’s land this blog post in style! . It-from-Bit . “… every it - every particle, every field of force, even the spacetime continuum itself - derives its function, its meaning, its very existence entirely - even if in some contexts indirectly - from the apparatus-elicited answers to yes or no questions, binary choices, bits.” . So says John Wheeler in Information, Physics, Quantum: The Search for Links, wherein he famously coins the term “It-from-Bit”. Wheeler was looking around at a few astounding facts about the universe and asking if these were hints that information itself may play a fundamental role in our universe. . Landauer and Limits . One of those facts is the link between even the simplest ‘computation’ - erasing a single ‘bit’ of information - and a completely unavoidable expenditure of energy required to do so. This is the famous Landauer limit: the minimum amount of energy $ text{E}$​​ it’s possible to use to perform the operation of erasing a bit (at a given temperature). The formula is pleasingly simple $ text{E} = text{k}_ text{B} text{T} ln2$​​ and at room temperature that’s $0.0175 text{eV}$​​​​ (our computers are several orders of magnitude more inefficient than this). . So computing gets pretty intimately tied to thermodynamics and entropy production - see The physical nature of information by Landauer for more. . Bekenstein and Black Holes . What else? Well there’s a finite amount of information we can pack into a given region of space! And conveniently enough, if you try to pack more information into that space (e.g. adding more bits of computer memory), you can show the whole thing would collapse into a black hole. This upper limit on the amount of information that can be packed into a given region is the Bekenstein Bound. . Staying with Bekenstein for a bit, in an article in the Scientific American titled Information in the Holographic Universe he noted that “Thermodynamic entropy and Shannon entropy are conceptually equivalent: the number of arrangements that are counted by Boltzmann entropy reflects the amount of Shannon information one would need to implement any particular arrangement”. It’s not about exactly the same thing, but I love this Eliezer Yudkowsky post which also points at the connection between knowledge of a system and ability to extract work from it. . There’s a further wrinkle involving Bekenstein here. He noted that if black holes are maximum-entropy objects (in-line with what we said above about not being able to squeeze more information into a region), then the entropy of the black hole scales with the area of the black hole’s event horizon. Insights like this gave us the so-called Holographic Principle, which says roughly5 “that the entropy of ordinary mass (not just black holes) is also proportional to surface area and not volume; that volume itself is illusory and the universe is really a hologram which is isomorphic to the information “inscribed” on the surface of its boundary”. . Qubits and dammit no-one’s name starts with a ‘Q’ . One of my 2020 Lockdown pasttimes was watching Leonard Susskind’s ‘Theoretical Minimum’ lecture series. At one point, Susskind is speaking about the logic of quantum mechanics, and the ways in which it is different from classical logic. He then makes a throwaway comment about a deep connection between the number of parameters in the qubit state space and the three dimensions of ordinary space. Not exactly ‘programming’ matter, but aesthetically I appreciate that the fundamental physics of two-state quantum systems just might link up in unexpected ways with the 3D world of everyday experience. . Topological matter . “Hey what’s your favourite programming language? C or Python?” . “Na dude, I only programme in the topological inequivalences of braided anyons” . We’re all familiar with the garden-variety of weird quantum phenomena - the double slit experiment, Schrodinger’s cat, etc. But beyond the garden wall there’s a veritable zoo of bizarre things. Wtf is a fraction of an elementary charge? What part of ‘elementary’ was I misunderstanding? What do you mean those made up mathematical ‘potential’ fields have physical consequences that are more fundamental than the good old electric and magnetic fields? . So here’s another thing: we can alter the properties of matter by creating knots in the hypothetical world-lines that they trace out in spacetime. What? I mean seriously, the idea is that in some dimensions, the topology (the properties of a shape that are preserved if we’re only allowed to smoothly deform it, without tearing or cutting) of some paths through spacetime has a measurable effect on the matter tracing out that trajectory. . I don’t know what things we might programme in this weird topological language. In a pleasingly-Ouroboros-like way, the most frequently given example for what topological matter enables is fault-tolerant quantum computers. . I say let’s programme matter with topology and then use that topologically-protected quantum state to programme everything else! . So is everything just information? . To round this off, Scott Aaronson has a great post on the extent to which information is physical. I recommend it in its entirety if you’ve enjoyed my minor foray into the topic. Here’s Aaronson on the fundamental importance of information in thinking about the double-slit experiment: . We get closer to the meat of the slogan [“Information Is Physical”] if we consider some actual physical phenomena, say in quantum mechanics. The double-slit experiment will do fine. . Recall: you shoot photons, one by one, at a screen with two slits, then examine the probability distribution over where the photons end up on a second screen. You ask: does that distribution contain alternating “light” and “dark” regions, the signature of interference between positive and negative amplitudes? And the answer, predicted by the math and confirmed by experiment, is: yes, but only if the information about which slit the photon went through failed to get recorded anywhere else in the universe, other than the photon location itself. . And so, even if we reject ‘It-From-Bit’, we must still account for ‘information’ - the very stuff manipulated by any program - in our most basic physical theories. . Conclusion . I hope you enjoyed this tour of the ways matter can be programmed, as well as the many digressions to speak about computing in general. For more in this vein, I highly recommend Michael Nielsen’s ongoing exploration of the future of matter. . Comments, twitter DMs, and links to more interesting stuff are always appreciated! . Also, I am working on part 2 of the FEP series, I promise! . More technically, an approximation, but it doesn’t really matter &#8617; . | I don’t have space or scope here to explain why we’re using vectors, or what all the symbols are. I know this is kind of unfair. But my argument in the rest of this post doesn’t depend on the maths specifically, it’s the general idea of representing pieces of math in physical systems that we care about. Also, another plug here for quantum.country - if you want to understand all the notation, they explain everything far better than I can! &#8617; . | If it sounds like he’s hedging a bit, he is, and the full interview explains the technicalities as to why, but as far as I can tell, he still believes that a quantum computer could simulate any finite physical process. &#8617; . | Actually, if we take seriously that biology and neural nets are similar, in that they were both created by very powerful optimisers (evolution and stochastic gradient descent, respectively) working on highly redundant systems, maybe there is an extension of this analogy that bridges our current approach of understanding biology to the approaches we use to understand the internals of deep neural networks? Interpretable deep learning has been a possible attack vector for understanding the brain for a while (see e.g. here: https://distill.pub/2021/multimodal-neurons/), but maybe there are wider applications? See https://distill.pub/2018/building-blocks/ for more on interpretability. &#8617; . | I’ll just quote Wikipedia directly here, presumably to frustrate my primary school teacher, who said never to do this &#8617; . |",
            "url": "https://jaredtumiel.github.io/blog/2021/08/14/programmable-matter.html",
            "relUrl": "/2021/08/14/programmable-matter.html",
            "date": " • Aug 14, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Hamming-Enablers and The Tech In Techno-Optimism - part 1",
            "content": "Robert Boyle (yes the one from high-school chemistry) kept a list of technologies he thought humanity should pursue: . . The list is surprisingly prescient, hinting at flying machines, submarines, life-extension, and psychedelics. . I too have a list (but alas, no highschoolers have heard of Tumiel’s Law) and this post is about that (the list, not the law). But first we have to talk about Hamming Enablers. . Hamming Enablers . Boyle penned his list in the 1600s, which means that 300 years ago it was possible for a smart natural philosopher to conceive of these things being possible. So why the ~250 year delay between the list and the Wright Brothers? Why are psychedelics only really entering the (clinical) mainstream today? Why is human longevity not a solved problem already? . Each technology will have its own story of economic, scientific, design, and production challenges, but the general point I want to get at is the gap between technologies we can easily imagine (or suspect are possible), yet don’t currently know how to tackle. . The easiest way to understand this is through the idea of a tech-tree in video games: you can’t just unlock nuclear power if you haven’t first researched mining, uranium refinement, the physics of nuclear chain reactions, etc. It’s easy for anyone to look at birds flying and know that in-principle, heavier-than-air-flight is possible. It’s more difficult to backchain to what intermediate developments in fluid mechanics, calculus, materials science, and powertrain development are needed to build an aeroplane. . . So what’s a Hamming Enabler? Richard Hamming (of Bell Labs fame) in his famous speech You and Your Research has this to say: . Most great scientists know many important problems. They have something between 10 and 20 important problems for which they are looking for an attack. And when they see a new idea come up, one hears them say “Well that bears on this problem.’’ They drop all the other things and get after it. . Gian-Carlo Rota, in his advice to his younger colleagues, quotes Richard Feynman, who offers a similar piece of advice: . Richard Feynman was fond of giving the following advice on how to be a genius. You have to keep a dozen of your favourite problems constantly present in your mind, although by and large they will lay in a dormant state. Every time you hear or read a new trick or a new result, test it against each of your twelve problems to see whether it helps. Every once in a while there will be a hit, and people will say, “How did he do it? He must be a genius!” . And it’s not just dudes from the 1900s who think this is something worth doing! Here’s Ed Boyden1 saying much the same thing: . … I really try to make my schedule safe for serendipity. I spend a lot of time going over old conversation summaries. A lot of the old ones are about ideas that ended in failure, the project didn’t work. But hey, you know what? That was five years ago, and now computers are faster, or some new information has come along, the world is different. So we’re able to reboot the project . So we have two rather-famous-Richards and neuroscience superstar Ed Boyden giving similar advice: know the ins and outs of a few particular problems, the current bottlenecks and limitations. Then as you bump into novel ideas, analytical techniques, manufacturing, or technical procedures, you can quickly ask yourself if the new thing could possibly enable progress on one of your pet problems. I call a new process, material, technique, model, mathematical paradigm, or physical law which enables progress on a difficult technical problem a Hamming Enabler. . Hamming Enablers are interesting retrospectively and prospectively. Retrospectively, we can ask why powered flight was not invented in the 1600s, or we can ask what had changed around 1903 that suddenly made it tractable. Prospectively, we can ask what tech a given new development might Hamming-Enable (does that make sense?), or reverse the question and ask what Hamming Enablers we might require to reach a certain technological goal (the backward-chaining idea I mentioned earlier). . So, without further delay, let’s step through the list2 . Computation, Intelligence, and Coordination . Heterogenous Compute, and Non-Von-Neumann architectures . Moore’s Law is slowing down, and every year chip-makers are doing their best to squeeze more performance out of semiconductor design. To the extent that they fail or fundamental physical limitations in the size of semiconductors set in, we’ll need to use other strategies to see continued progress in computing power. . The Apple M1 chip is a good example here: the M1 is what’s known as a System on a Chip (SoC). Instead of each component in the computer plugging into a motherboard, the whole thing is on one piece of silicon, minimising distance between components and allowing for optimisation of the unit as a whole. . At the extreme end of hardware specialisation we get Application Specific Integrated Circuits (ASICs). Here, we just hardcode the program we want to execute into the logic gates of the processor, sacrificing the flexibility of more general architectures for pure speed. . Heterogenous compute captures the idea of combining ASICs into our devices (laptops, smartphones, self-driving cars, etc.) for some of the most common tasks, thus getting the speed and efficiency benefits of an ASIC while preserving the generality of the device. For example, the iPhone has a dedicated image-processing chip alongside its general processor, and we can imagine generalising this for almost any device that finds itself performing one or two computations far more often than any others. . An obvious area we’ll see something like this in is in AI-specific hardware. TPUs (tensor processing units) are already one attempt at this, but we can do better. If we think of computing as a process happening in a specific medium, with a specific architecture, then we can ask if there are other computational mediums, and other computational architectures that might be useful. Right now, the medium we use to compute is electronic - electrons in moving in transistors, and the architecture is essentially3 the Von Neumann Architecture. . Beyond Electronic Compute . Moving electrons around has its limits. There’s resistance and heat dissipation to think about, as well as their mass and the amount of energy needed to move them at a given speed. Photons on the other hand… also have a bunch of problems as a computational medium (hence requiring progress in materials science), but they don’t have mass, so that’s a start! . . Nonetheless, some concrete progress has been made, especially if (in keeping with the heterogenous compute theme above) you restrict the types of operations you want to perform. Modern deep learning requires a lot of matrix multiplication, and it seems like there’s been relatively more success using light to compute in this setting: . Researchers have shown dramatic efficiency improvements in training neural networks using photons. | A startup called LightOn AI has developed an entire photonic processor. This is cool because they used this processor to implement a non-standard algorithm for training neural nets called Direct Feedback Alignment, which touches another theme from later in the post. I’ll have more to say about going ‘beyond backprop’ in the AI section of the list, but noting how items on this list are synergistic and Hamming-Enable each other is like half the reason I’m so excited. | . Beyond Von Neumann Compute . Our abstract model of computation comes from the Turing Machine. But we want a concrete implementation if we’re to do any actual computing (ain’t nobody got time for an infinitely long tape). John von Neumann gave us his eponymous architecture, and it’s pretty recognisable in just about any computing-device you’re likely to have. It consists of inputs (touchscreen, mouse, keyboard), a CPU which executes the instructions made by programs, external memory, which stores data and programs, and some outputs (screen, printer). Note that the CPU and memory are separated, meaning data needs to be transferred between the two. The von Neumann bottleneck refers to the limitation imposed on the speed of computing because of the latency introduced by this data transfer. What’s worse is that while we’ve both sped up our CPUs and increased the density and capacity of our memory, the rate of data transfer has remained relatively stagnant, meaning the von Neumann bottleneck has gotten worse. We get around it with a bunch of tricks like RAM, caches, and multithreading, but as a limitation its baked into the way we build computers. . So what if we just didn’t do that? These are the so-called non-von Neumann architectures, and at their most basic they try to find a way to do ‘in-memory’ computing, so that the CPU doesn’t have to wait around for data to be shipped-in from memory. A subset of these go by the name ‘neuromorphic compute’ because of some (loose) analogies to biological neurons. This is also a form of heterogenous compute, and one of the main reasons to make a neuromorphic computer is to allow for more efficient use of artificial neural networks, which is a nice synergy to have if AI is going to be increasingly important! . . AI . Having a section like ‘AI’ in a list of things to be optimistic about is too broad, and not exactly a revelation to anyone likely to be reading this. Like all of the things on this list, the people working in this field tend to role their eyes at lists like these because they actually know enough about the day-to-day challenges of the work to know that something simple sounding like “use AlphaFold to enable the next generation of drug discovery” is sweeping a lot of practical tedium under the rug. This is probably true for everything on this list, so we might as well acknowledge it here. . So what, specifically is happening in AI right now that should give us optimism? . One is just a personal hunch, and that is that there really is progress in the field. I don’t have a legible description here, but AI right now feels alive and generative in a way which few fields do. Another personal hunch is that there are many specific techniques which are aimed at solving individual problems getting pushed to Arxiv daily, and no one has the time to pick the low-hanging fruit of combining them. By this I mean that for many of the specific problems someone could point to with AI, someone is publishing something to the Arxiv that addresses it. It might not solve it completely, or it comes with tradeoffs, but the turn-around times are impressive. . For example, let’s use the relative inefficiency and large computational overhead of using Transformers in all the super powerful GPT-X-esque language models. Models like these come under fire by AI critics, who cite the cost and environmental impact of using all those GPUs, or the amount of data needed to train the model, as problems. But then, in the span of just 6 months (from January to June of 2020) there were several different proposals addressing both these issues, including the Reformer, the Performer, the Linformer and others with less catchy names. . On one hand. I can imagine a sceptic saying something like “those are just incremental improvements pushed out to get citations”, but a) it’s absolutely awesome that the field moves fast enough that multiple serious solutions are posted so quickly to serious challenges, and b) the incentives of academia are not set up for researchers to refine those techniques and set them up for production-level AI, let alone combine disparate improvements across research labs and productionise the combination, making them seem more incremental than they really are. The times where this has happened (e.g. the pretty standard combination of ResNets + dropout + SGD + batchnorm for many computer vision tasks) has produced phenomenal results, and importantly, each of those techniques seems to work synergistically with the others. My gut feeling is that there are other unexplored, unrefined (to production-level, not academic research level) combinations just waiting to be plucked from the Arxiv! . Okay, enough “gut feelings” and “hunches”, let’s be concrete! . First, my one paragraph summary of how I see the state of AI right now: . Humans have “solved” many of the original challenges of the field (image recognition, text generation, game-playing), mostly using classique supervised deep learning. Big efforts will be made to continue adding parameters to Transformers to see when, if ever, this stops improving their performance. Current success is largely due to some brilliant architectural and training tricks, all mashed together with oodles of labelled data from the internet and lots of computing power. Transfer learning makes these pretrained models available to anyone and so now anyone can benefit from that one time outlay of compute to build more specialised models. Reinforcement learning remains more challenging, but things like MuZero look seriously promising. . So what’s new: . Well self-supervised learning seems to be going through a bit of a renaissance. A big sticking point in AI right now is the availability of labelled data from which to learn, and the ability to do common sense reasoning even on situations you haven’t specifically trained on. Self-supervised learning tries to address the former by learning something about the (statistical) structure of the data in general, and in doing so, possibly improve at the latter. A few new approaches have surfaced recently, often using the idea of “contrastive learning” to setup the agent to try and predict unseen parts of the data, given the context of seen parts - no labels required! I think some scheme like this is one way we could build robust world models for our model-based RL agents, and I think good world models are the key to some of the “common-sense” reasoning some people bemoan AI for lacking. . Another thing I’m optimistic about is AI augmenting and enabling new physical possibilities. It seems many people currently think of ‘AI’ as either the thing that makes your Instagram feed eerily mirror your innermost thoughts, or something to do with making robot dogs walk around. Instead, what we should focus on is that we have a decade of experience training optimisers that are extremely good at traversing high-dimensional spaces, and now we get to choose whether that space is about which ad to serve you on YouTube, or about the tiny proportion of physical arrangements of molecules that generate a particular response in a petri-dish of cells. . AI for scientific discovery is an obvious Hamming Enabler. Right now, a group of researchers can discover new facts about physical materials just by exploring the latent space of a language model trained on the materials science literature. More generally, we can think of doing reinforcement learning in unique state-action spaces4. So instead of imagining an agent being able to choose how to move through a physical environment using familiar actions to those available to us as humans, we could imagine our state space as being the molecules present in a beaker, and which are bound to which and in what positions. The action space could be the set of known chemical reactions, or application of some catalyst, and the agent could have the objective of creating a molecule we specify before-hand, but don’t currently know how to synthesise. . Generative design also seems relevant to point out here. It’s a neat bonus of most models that once you’ve trained them to (e.g. in the case of AlphaFold) predict protein structure from the amino-acid sequence, you can probably invert them and do the reverse, or you can use the latent space that encodes all the knowledge to ask further hypothetical questions about protein structure. A lot was made about drug-discovery using AlphaFold, but I tend to think of it as the first steps towards AutoCAD for molecular machines (and believe me, proteins aren’t just ‘like’ molecular machines. Proteins are molecular *machines! [paywalled]). So predicting proteins accurately is certainly impressive and useful, but my guess is that there’s far more value to be extracted by some combination of an RL agent able to act with something like AlphaFold as its world-model. That being said, the state of AI+protein design is stupendously exciting - just look at Einstein.ai’s use of language models for protein design! . More than this, I think the people trying to do something different from just scaling up Transformers have a chance of making a breakthrough. Self-supervised learning is part of this, but some even more fundamental shifts are afoot. I continue to think that Karl Friston’s Active Inference, and the related Free Energy Principle, will have important things to contribute to mainstream AI. Early signs of this are: . Active inference based models outperforming traditional ones in the non-stationary multi-armed bandit task (paper). | Active inference encompassing and extending traditional reinforcement learning (paper) | Active inference ideas making their way into publications by big, industry facing research labs like DeepMind (paper) | Predictive coding (key neuroscientific account of brain function, heavily studied by FEP/active inference crowd because of formal similarities) shown to approximate the backpropagation algorithm (key ingredient in training our current deep neural nets) (paper) | . More things to be excited about: . I remain excited about neural net architectures that take advantage of the structure or symmetry of the data - gauge-equivariant neural nets, graph neural nets, geometric deep learning - all seem full of possibility | Architecture search as well as learning to create optimisers which learn to train themselves point to a path where “end-to-end” ML means also learning an architecture and an optimiser that’s particularly suited to your task. Related: the lottery ticket hypothesis and possibly using this to enable much smaller edge networks | Physical neural networks. Heavily related to heterogenous compute above, but there’s even more awesome stuff in the mix which I think has barely been explored. I have an entire blog post in the works about these! | Neural cellular automata. The extensions already created to this idea are crazy. See: Towards Self Organised Control and Growing 3D Artefacts and Functional Machines with Neural Cellular Automata. As a heuristic model of complex system development, and a way of creating robust self-organising systems, I think this is a promising direction of research. | . Crypto . and thus the transformation into tech-bro was complete . Crypto gets a bad rap. For many it’s the perfect combination of the vitriol and tribalism of the internet, muddled up with the embarrassment, fear, and greed of personal finances. But there are some specifics about crypto that excite me, especially if we think of it as a general Hamming Enabler for a host of heretofore untried experiments in social coordination, cooperation, fundraising, and governance. . As a warm up to the possibilities, let’s contemplate this tweet: . . I think this matters because of 2 things: 1) permissionless innovation, and 2) fast feedback loops (bonus for the feedback in crypto usually being monetary, so the incentives are pretty real from the get-go). . Arguably one of the big reasons we had such big slowdowns in innovation post-1970 is that we regulated away our ability to innovate. If you need millions of dollars in lobbyists, and years of filing paperwork to get your HyperLoop installed, it’s probably going to be really hard to iterate fast enough to make mistakes and learn from them, and you wouldn’t want to because delays and redesigns will be costly and subject to more paperwork5. Compare that to the relatively unregulated software sector from 2000-2016, where (even if bad things have happened), it’s hard to deny that e.g. the ideas and implementation of companies like Uber and AirBnb are innovative approaches to solving their respective problems. . Crypto, if nothing else, has opened up another frontier for people to play around and try out new ideas. Specific coins may come and go, and scams will be inevitable (sort of like the early internet), but at the same time a core of dedicated, super-smart people with genuine morals and a desire to create something important will be working away like crazy in the background. Take a look at Numerai for an example of something which I would claim was Hamming-Enabled by the development of cryptocurrency. I also think that we’ll see the DAO concept continue to develop and mature, which might itself Hamming-Enable new ways of funding research and other public goods. Plus, there’s never been a better time to be a mechanism design researcher, because suddenly you can try out fancy things like Quadratic Funding, at scale, in the wild, and learn from that. . More things to be excited about: . Ethereum scaling solutions (optimistic and ZK-rollups) + sharding in the longer term look like they will work, and when they do I think of them as being Hamming Enablers for the entire Ethereum ecosystem | Lots of individual things in the DeFi space. It’s a bit of a contrived example, but think about flashloans for a second. The fact that suddenly anyone on earth can borrow hundreds of millions of dollars with zero collateral and no need for a credit check is wild. So far it’s mostly been used for arbitrage opportunities (and attacking/exploiting liquidity farms), but as Hamming-enablers go, if we’re just asking the question “what’s something that’s now possible that previously wasn’t?” this is one of those things. I think we’re all just waiting for someone smart to show us some new, powerful application that no-one else has thought of yet. | . Progress, Institutions, and Politics . Progress Studies &amp; Techno-Optimism . Yes, I’m optimistic about the optimists . Stagnation - both technological and economic - is bad. Luckily, having identified the shape of the problem (or at least maybe the year it started?), we can start to look for solutions. The “progress studies” crowd6 - a group of people determined to understand the causes of productivity stagnation and how we can return to or even exceed previous high levels of growth - is a great signpost to others that we should-and-do care about pushing society down a path of growth and technological development. . I think there’s a whole conversation to be had about the kinds of memes we distribute and the extent to which our media and our civilisational storytelling can be a driving force for progress. Personally I find reading the techno-optimists to be infectiously optimism-inducing, and I think that’s a flywheel worth spinning up! . PARPA, New Science, Focused Research Organisations, and all that . Is scientific progress slowing down? And if it is, how much of that is due to intrinsic factors (e.g. picking all the low-hanging fruit to be discovered) versus something about the way we do science? I am strongly in favour of diversifying our funding models and talent-selection-institutions, and that’s why I’m excited about proposals like Private DARPA by Benjamin Reinhardt, or Focused Research Organisations by Adam Marblestone and Samuel Rodriques, or Alexey Guzey’s New Science. It’s also why I’m optimistic about crypto because, on the margin, having a different cohort of wealthy people with a higher than average predisposition towards techno-optimism, enabled by new mechanisms like DAOs and various yet-to-be-invented smart contracts, seems like it could enable a bunch of people to contribute towards R&amp;D who otherwise wouldn’t have! . Charter Cities . The basic idea of a charter city is this: a bunch of people approach a nation-state and negotiate some contract to create a special jurisdiction somewhere in their country and build a city. The city builders get to experiment with best-practices in-governance, and can use the blank-slate to try encourage (i.e. set up innovative incentive structures) especially high rates of growth, entrepreneurship, sustainablility, or whatever the founders and the population care about. In exchange, maybe they funnel some percentage of the city’s taxes back to the nation state, leaving everyone better off than if there had been no charter city. . Again, in the spirit of letting a thousand flowers bloom, I think the charter city space is exciting. This follows because, if you think that maybe we’re hindering our ability to build by regulatory-strangulation, having diversity of regulatory environments will allow for more experimentation. . Scott Alexander has been doing a great job of dissecting various attempts at creating charter cities and things like them, and also has a detailed review of the charter city, Próspera. . Mechanism Design &amp; Social Technologies . I think two big Hamming-Enablers for meaningful mechanism design will be the combination of usable augmented/virtual reality devices (think e.g. a pair of glasses that could overlay everything you currently see on your iPhone onto the world in front of you, so no need to look down or stop what you’re doing) and the crypto stuff we’ve talked about earlier. The AR side helps us bring our digital incentive tools out into the physical world. The crypto side is useful for creating ecosystems with financial incentives and rules enforced by code. . I think that coordination problems problems and inadequate equilibria are at the root of much of what’s wrong in the world currently, and that, even though they’re amongst the hardest problems out there, on the margin it’s worth investing in technologies that mitigate them. If we’re going to become a ridiculously powerful civilisation, we’re going to need ways to coordinate and prevent e.g. AI-arms-races, or further nuclear-proliferation, or any race-to-the-bottom where ‘the bottom’ = civilisational destruction. . On a less existentially-critical note, designing better policy and incentive structures is worth thinking about generally. I remain a fan of Glen Weyl’s RadicalxChange project, and his book with Eric Posner was the thing that convinced me that there could be solutions to these sticky coordination problems at all. On a related note, I’ve enjoyed reading Samo Burja’s analysis of the importance of social technology in creating and sustaining successful institutions. . Meaningness, and meta-rationality . This last entry might seem out of place on a list that’s been primarily technology-focused, but if we are to increase our power over the universe, we should invest a commensurate amount of energy in learning to use it wisely. I think the EAs and other longtermists are making a good start here, but something that’s made the most difference personally is David Chapman’s work at Meaningness, Vividness, and on metarationality. . It’s hard to say where to start because his writing is this sprawling nebulous living document, but here, here, and here are pretty solid jumping off points. Chapman gently builds up a framework for dealing with the dimensions of what he calls “meaningness”. The tagline for the site is “Better ways of thinking, feeling, and acting—around problems of meaning and meaninglessness; self and society; ethics, purpose, and value.” and it’s pretty accurate. It’s hard to try and vouch for this particular set of ideas about meaning without sounding like every other religion/cult/self-help-guru trying to advocate for their favourite One True Solution to Your Life’s Problems. Thankfully, Meaningness isn’t meant to be a self-contained personal philosophy that’s fully general. Actually, that’s kind of one of Chapman’s points - that no system can ever be final and all-encompassing. It’s the thing I’ve recommended most often to friends when they’re having problems that can’t be solved with a debugger or a trick for doing a weird integral. . Conclusion . What have I left out here? What else is there to be excited about? Obviously this list is far from exhaustive and is more ‘personal opinion’ than me saying “objectively these things are the best”. . The list continues in part 2, where I talk about everything I’m excited about in Materials, Molecules, and Manufacturing as well as Biology, Medicine, and Biotechnology. If there’s anything you think I should check out in those areas before then, my twitter DMs are open! . Ed Boyden’s lab birthed both optogenetics and expansion microscopy, which have both been gigantic Hamming-Enablers in neuroscience research &#8617; . | Initially, I wanted to work through the Hamming Enablers for each thing on my list - both in terms of what is now enabling that thing, and what it might be a Hamming Enabler of, but honestly I just don’t know enough about many of the ideas to reliably do that, so instead I’ll leave some of it as an exercise for the reader. I think the list has value in-and-of itself so I’ll include it in its entirety &#8617; . | Yes yes, Harvard architecture. But Non-Von Neumann sounds cooler than Non-Harvard &#8617; . | In RL, the state space is all the possible states the agent could be in. Typically this would be positions in a gridworld. The action-space is the space of available actions e.g. at every timestep pick one of [walk left, walk forward, walk backward, walk right, stay still]. My argument is that people tend to forget that state/action spaces can be a whole lot more abstract than that, and that enables a lot of exciting applications &#8617; . | maybe the thing I admire most about Elon Musk is the fact that he actually tried to innovate in a bunch of these areas that are prototypically stymied under regulatory nonsense (spacetravel, energy, full-self-driving) &#8617; . | See for example the excellent https://rootsofprogress.org/ &#8617; . |",
            "url": "https://jaredtumiel.github.io/blog/2021/08/06/techno-optimism1.html",
            "relUrl": "/2021/08/06/techno-optimism1.html",
            "date": " • Aug 6, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Spinning Up in Active Inference and the Free Energy Principle",
            "content": "A few months back I posted the first part of an introduction to the Free Energy Principle. I did this because it’s fascinating and important, and yet sometimes comically difficult to learn about. A big part of the problem is probably Research Debt - a dearth of digestible translations of cutting-edge research into something accessible to non-specialists. My FEP Explained posts are aimed at this problem, but this post is aimed at another: not knowing where to start or where to go! . . For most things humans care to learn, someone has trod the path before and shown the way to others. There is a common starting point (usually the end of high school) an endpoint (doctor, physicist, architect, etc.), and a routine path to take between these two. The FEP has none of these. The researchers tend to come from lots of different backgrounds, so everyone has things they know well, and things they need to learn. There isn’t a clear end-point aside from “understand what’s going on, maybe add to our understanding someday”, and the complete path is not routine enough that there are any university degrees or courses entirely about the FEP. . What we need is a syllabus! A list of material that gives you the necessary background to understand the full Free Energy Principle (and Active Inference), which also functions as a reasonably complete map of the territory so that people can quickly see what the field encompasses and how the parts relate. Our syllabus should cater to the kinds of people who end up interested in the FEP, so should include different starting points and different levels of technical detail. It should gradually improve you, filling in details as you become able to digest them. Lastly, it should challenge you to act and solve new problems - problems you couldn’t have solved before you went through it. . This is a first attempt to do some of those things. Each section has a short motivation, and some of the materials have descriptions where I thought it useful. At the end, there’s a section on Open Problems and Future Research directions which I need your help filling out, so please comment on this post or reply to the Twitter thread! . How to use this syllabus . Generally, dive in. Don’t wait to finish all the prerequisites before you try getting your head around the theory. Jeremy Howard from Fast.ai has this great line about getting a feel for something by playing around with the full construct before you fully understand it, and once you have a feel for it, only then do you go learn the technical details. So even though this list starts with “prerequisites”, treat that as a placeholder, go until you get stuck, and then come back and see if you can find the answer to the stuck-feeling in one of the prerequisites. . I’ve also tried to have a hierarchy of materials within each category, starting with short, intuitive primers and ending with longer, more technical material that only becomes relevant as your interests deepen. There isn’t a strict order to the materials, which is why it’s probably better to go iteratively deeper across all the categories, instead of linearly down the list. . Prerequisites . Neuroscience . The FEP came out of Karl Friston’s neuroimaging work, so it shouldn’t be surprising that neuroscience is a key competency. . Predictive Coding/Predictive Processing . Predictive coding is a theory of how the brain works that inverts the traditional “bottom-up” feature detection view and replaces it with the brain generating top-down predictions instead. When a prediction does not match with what is actually observed, an error signal is passed up through the brain and changes take place to minimise the prediction error in the future. . Predictive processing is closely associated with the FEP, and naturally “emerges” from the equations governing the FEP. In this sense, understanding PP is helpful to have an intuitive view of what the FEP achieves in the brain. . It’s Bayes All The Way Up by Scott Alexander [blog] Scott has a great series of posts on Bayesian brain hypotheses. A nice way to get some intuitions! | . | Bit of a Tangent [podcast] This is cheating, but we did a series of three podcasts on PP, so check those out if you prefer audio | . | Surfing Uncertainty by Andy Clark [book] This technical book gives a deep introduction to much of the theory behind PP, but still manages to be accessible to non-neuroscientists (I’m not one). It’s really good for getting an overview of the PP literature and the flavour of this view of the brain! | Scott Alexander also has a great review of the book here | . | . Computational Neuro and modelling techniques . Part of the appeal of the FEP is that it might lead to improved models of the brain and biological intelligence. Learning to set up experiments, design simulations, and implement models of neural systems in code is a big part of turning the theoretical results of the FEP into a powerful set of new tools and applications! . Neuromatch Academy [summer school/course][virtual] This is a fully-online Summer School with all the materials freely available. It includes all of the content you need to get started in computational neuroscience and includes deep learning and reinforcement learning content too! The content has been created and curated by a great team of researchers and their explicit goal is to train people from diverse backgrounds in computational neuroscience! | . | The Imbizo [summer school/course][in-person] If/when international travel ever becomes possble again, I cannot more strongly recommend attending the annual Computational Neuroscience ‘Imbizo’ in Muizenburg, South Africa. It’s basically a three week crash course in computational neuroscience with a bunch of awesome speakers and students. It’s easily the most fun I had in 2020, and I learnt a tonne! | . | Computational Psychiatry course [course] One of the promises of the FEP is a new understanding of the computational basis of psychiatric disorders such as depression, schizophrenia, ADHD, bipolar-mood disorder and others. This course is an introduction to understanding these conditions computationally and mathematically. The course materials are all online, and Karl Friston himself has given some of the lectures in previous years! | . | . Control Theory/Cybernetics . A huge part of the FEP has to do with acting on the world! We need to keep our physiological parameters within tolerable limits, using feedback loops and the techniques of control theory. Understandnig the history and techniques of these fields helps us contextualise the problems the FEP and active inference set out to solve. . Mind In Motion: How Action Shapes Thought by Barbara Tversky [book] | Classical Control Theory by Brian Douglas [videos] A short but useful introduction to control theory from an engineering viewpoint | . | Understanding PID Control by MatLab [videos] | Control Bootcamp by Steve Brunton | . | . Physics . The Free Energy Principle wants to explain how we, as biological organisms obeying the laws of physics, can self-organise into complicated creatures that maintain our complexity despite (or because of) dissipative forces. The FEP rests solidly on the ideas of modern physics, so the more you know here the better! . Statistical Mechanics . Entropy, Free Energy, non-equilibrium steady states - these ideas are front and centre in the FEP literature and all come from stat-mech. If you were going to spend your time learning about only one area of physics to really have a good basis in the FEP, this is probably the one you’d pick. . Statistical Mechanics in The Theoretical Minimum by Leonard Susskind [lecture videos] Leonard Susskind is a hero to me. I’ve heard more than one person say that they did multiple stat-mech courses and the derivation of the partition function was never as magically clear as Susskind’s. If you’ve never done any stat-mech, this is a good place to start! | . | Statistical Mechanics: A Set of Lectures by Richard Feynman [textbook] The Feynman Lectures on Physics are rightly famous for their explanatory clarity, but less well-known are his lectures on statistical mechanics! Worth reading just because it’s Feynman! | . | . Non-equilibrium Statistical Mechanics . Of course, the FEP deals with living systems, and living means being far from thermodynamic equilibrium, so we’ll want to understand how to describe these systems mathematically. The big ideas that come up often are non-equilibrium steady states, as well as the Langevin and Fokker-Planck equations. . Non-equilibrium Statistical Mechanics by the Indian Institute of Technology Madras [lecture videos] Professor Balakrishnan is legendary on YouTube for the clarity of his explanations. The course is genuinely great and includes lots of detailed explanations of the Langevin and Fokker-Planck perspectives on dynamical systems! | . | A Worked Example of Fokker-Planck based Active Inference by Magnus Koudahl &amp; Bert De Vries [video] This is a great direct introduction to using the Fokker-Planck equation in the FEP! It’s especially useful if you’ve read a few papers and can’t make sense of the notation - this is the clearest description I’ve found! | . | Nonequilibrium Statistical Physics: A Modern Perspective by Livi &amp; Politi [textbook] Both this book and the one below contain detailed derivations of the techniques used for non-equilibrium stat mech. They’re both similar, but Attard’s book has more focus on entropy and the second law of thermodynamics, whereas Livi spends more time on critical phenomena. | . | Stochastic Thermodynamics, Fluctuation Theorems, and Molecular Machines by Udo Seifert (2012) | Non-equilibrium Thermodynamics and Statistical Mechanics: Foundations and Applications by Attard [textbook] | . Classical Mechanics, Hamiltonian Mechanics, and the Principle of Least Action . Friston sometimes frames the FEP in terms of a principle of least action, where action is an integral over a nice object called a Lagrangian. Lagrangians and Least Action principles give us a really powerful way to describe the equations of motion, symmetries, and conservation laws of our system, so knowing about this approach is really worthwhile. That being said, this approach doesn’t feature prominently in the basic formulation of the FEP, so don’t get stuck here! . Classical Mechanics by Leonard Susskind [lecture videos] Like his Stat-Mech course, Susskind does a good job of getting the main ideas across with just enough maths to allow you to understand more formal treatments later. | . | . Gauge theory . Gauge theory is a way of describing how certain symmetries in our system can lead to new properties/forces. It’s not a big part of the core theory, but I include it here because it’s a personal favourite, and Friston and collaborators have dabbled in applying some gauge-theoretic ideas to the FEP. . Gauge Theory - The Biggest Ideas in The Universe by Sean Carroll [video] | Physics From Finance: A Gentle Introduction to Gauge Theories by Jakob Schwichtenberg [textbook] This is about as an intuitive introduction to the idea as you could ever get. Schwichtenberg actually starts off with an easy financial model and then uses that analogy to build up to the use of gauge theories in particle physics. | . | . Maths . I kind of want to say that I’m taking it for granted that you know at least a bit of multivariable calculus, some linear algebra, and some probability theory (the FEP people definitely assume this, and more), but also I didn’t know any of those things when I started (not so long ago!) and felt really helpless when they were just assumed, so the above links go to the MIT OpenCourseware courses I used to get going! . Bayesian inference . The FEP fundamentally deals with agents trying to infer the state of their environment, given their current sensory data. Whenever you have a sentence like that, Bayes’ Theorem can’t be far behind! Understanding, on a gut level, the mechanics of how Bayes works, and being able to fluidly work with the different forms of the formula (knowing some basic identities in terms of joint distributions and marginal distributions) generally makes a lot of things in the FEP clearer! . An Intuitive Explanation of Bayes’ Theorem by Eliezer Yudkowsky [blog] I link to this article all over the place because it’s just so good. It won’t teach you to use Bayesian techniques in your machine learning model, but it will teach you why you’d want to! | . | Probability Theory: The Logic of Science by E.T. Jaynes [textbook] Rederiving probability theory from scratch might be overkill, but this book sort of reads like the Feynman Lectures, but for probability theory. Be sure to grab the unofficial errata | . | Machine Learning: A Probabilistic Perspective by Kevin Murphy [textbook] This is pretty lengthy but for the first 3 chapters (reintroducing key ideas in machine learning, probability theory, and generative models) are a quick way to get up to speed with a lot of the jargon, if you’ve already done a bit of probability theory beforehand! Chapter 5 on Bayesian statistics and chapter 21 on variational inference (see below) are especially relevant to the FEP! | . | . Information theory . Entropy, confusingly, moonlights as a term in information theory. Not only that, but since much of the FEP is about a system inferring the state of a hidden (latent) variable through its noisy sensory signals, the techniques of information theory (invented by Claude Shannon for almost exactly that kind of problem) are key. Information theory also teaches us about the Kullback-Liebler divergence, which is worth knowing just on its own! . Shannon Entropy and Information Gain by Louis Serrano [video] This is a good intro video covering a lot of what you need to know when you’re just getting started | . | A Short Introduction to Entropy, Cross-Entropy, and KL-Divergence by Aurélien Géron [video] I’ve watched this video at least 5 times. It’s a brilliant introduction to some genuinely challenging concepts in a way that leaves you feeling like everything finally makes sense! | . | Information Theory, Inference, and Learning Algorithms by David MacKay [textbook] This freely available textbook contains a lot more detail than the two intro videos. It’s a good place to look if you have nitty-gritty information theory questions. | . | . Information geometry . Depending on your feelings about math, information geometry is either a sort of sublime union of differential geometry and statistics, or a Frankenstein’s Monster of two other monsters. Information geometry lets us do statistics on manifolds, which seems arbitrary (especially if you don’t know what a manifold is), but might be useful, and is at least very cool to say to your friends. Friston occasionally mentions the term, so this is here as a reference you can return to for when he does. . Information Geometry by John Baez [notes] These notes are packed with insights about geometry, entropy, dissipative forces, and more! Most importantly, they feature a neat derivation of the Fischer Information Metric, which is a big part of the field. I really enjoy the way that John C. Baez explains maths - he manages to make me feel like I really could have done that when he derives something. A bonus of these notes is Baez riffing on how this information geometry applies to evolutionary systems, and the relative entropy (aka the KL-divergence!), so you can see a lot of the bread and butter of the FEP infused into this field! | . | . Computer science and machine learning . The FEP will remain an intriguing bit of mathematical theory if good programmers don’t start to find ways to apply the ideas to problems in artificial intelligence and machine learning. On the other side, ideas from AI/ML are key to understanding where the FEP and Active Inference can fit in and what the current state-of-the-art is. . Deep Learning . Deep learning has been so damn successful that it’s worth knowing about just for that. Neural networks are great function-approximators, which can be useful in the FEP. Also, the standard deep learning libraries (PyTorch/Tensorflow etc.) are worth learning because they make it really easy to build flexible models using current best-practices, and they make things like autodifferentiation and optimisation easy! . fast.ai by Jeremy Howard and Rachel Thomas [course] An excellent, practical introduction to state of the art techniques in modern deep learning. Emphasis on deploying models. Worth it just for Jeremy Howard’s wisdom. | . | Advanced Deep Learning and Reinforcement Learning by DeepMind [lecture videos] A more detailed course which picks up a lot of the detail that Fast.ai leaves out. | . | Deep Learning Book by Ian Goodfellow, Yoshua Bengio, and Aaron Courville [textbook] Not so relevant to the FEP, but so so good and freely available! If you ever want to know more about deep learning, it also has a great set of introductory chapters on calculus, linear algebra, and probability theory, which just give enough to get started in the general area, rather than doing entire university courses! | . | . Reinforcement Learning . RL is currently the most established field for creating autonomous, intelligent agents that can interact with their environments. Knowing the basics of how RL has approached intelligence, what kinds of techniques are available, and their limitations, helps us put the FEP in context. RL also deals heavily with Markov chains and the Markov property, and has established techniques for programming these kinds of agents. All of this can be transferred into the design of FEP-style agents. . A nice side-effect is that RL has a bunch of established benchmarks and environments for testing how intelligent an agent is (like OpenAI Gym) and I think it’s key to the future of the FEP/Active Inference that their techniques can be shown to compete with (and eventually outperform) pure-RL models. . Introduction to Reinforcement Learning by David Silver [lecture videos] The classic intro course! | . | CS285: Deep Reinforcement Learning by Sergey Levine [lecture videos] Where the DeepMind course with David Silver introduces the ideas of traditional RL, this course goes into the details of modern deep RL. My brother recommends it highly | . | OpenAI Spinning Up in Deep RL A syllabus for learning RL on your own, and the inspiration for this post! | . | . Variational inference . At the start of your journey into the FEP, you’ll keep hearing about ‘surprisal’, ‘the ELBO’ (evidence lower bound), ‘variational Bayes’, and ‘model evidence’. For whatever reason, I took too long to just go and find out that all of these ideas are well established and well explained in the field of variational inference. Variational inference involves trying to infer an (intractable) probability distribution by using the techiniques of mathematical optimisation to make a starting distribution closer to our (intractable) target distribution. . Variational Inference and Deep Learning: An Intuitive Introduction by Alex Lamb [video] | Variational Inference: Foundations and Innovations by David Blei [video] | Machine Learning: Variational Inference by John Boyd-Graeber [video] | Variational Algorithms for Approximate Bayesian Inference by Matthew Beal [thesis] The PhD thesis Friston cites frequently and the source of many of the key equations used in the FEP | . | Derivation of the Variational Bayes Equations by Alianna Maren [paper] A friendlier explanation of Beal’s thesis, specifically for the FEP! | . | . Generative models . Close your eyes and imagine a red bus! If you can do it, maybe that counts as evidence to you that your brain has some sort of generative model (i.e. can imagine/synthesise plausible data points). More generally, generative modelling tries to explain the data we’re observing as being generated by some smaller set of (latent) variables. The FEP deals heavily with the language and ideas of generative models, so reading up on directy is helpful! . Modern Latent Variable Models by DeepMind &amp; UCL [video] | Probabilistic Graphical Models by Eric Xing (also see course website here [course] I enjoy this course for taking a different perspective on ML/DL. There’s a lot of variety, and the course has videos on variational inference and generative models. There are also slides and course notes here | . | . The Free Energy Principle and Active Inference . The main event! . General introductions . God Help Us, Let’s Try To Understand Friston on Free Energy by Scott Alexander [blog] | Karl Friston on Brains, Predictions, and Free Energy by Sean Carroll on The Mindscape Podcast [podcast] Sean’s interview with Karl Friston is my favourite of his ‘popular’ appearances. Sean Carroll really got some great detail and explanations from Friston | . | Karl Friston: Neuroscience and the Free Energy Principle by Lex Fridman [podcast] | Of woodlice and men: A Bayesian account of cognition, life and consciousness an interview with Karl Friston by Martin Fortier and Daniel A. Friedman [transcript] This interview with Friston delves into the history, philosophy, paradoxes, and clinical tie-ins of the FEP. I found it really helpful because I find it easier to understand a field if I know how it came about - it helps you see why those particular bricks were laid in that place. It reads really easily, and it has some ideas I’d wondered about but never seen in the literature (like the relationship between the FEP and David Marr’s famous Three Levels of Analysis) | . | . Technical introductions . Active Inference Podcast by @InferenceActive [podcast] This is a weekly podcast/journal club on the FEP/Active Inference. They’re detailed and the participants are active researchers in the field, so it’s a great way to hear their thoughts on some of the field’s key papers | . | Tutorial on Active Inference by Oleg Solopchuk [blog] | How To Read Karl Friston in The Original Greek by Alianna Maren [blog] | The Free Energy Principle and Active Inference by Kai Ueltzhöffer [blog] This post and the two below it are my favourite blog posts on the FEP. They come with enough math to understand it on a deep level, the explanations are intuitively satisfying, and I really enjoy the | . | Introducing The Deep Active Inference Agent by Kai Ueltzhöffer [blog] A great technical discussion of using deep learning to improve active inference! Notably, there is working code you can play around with and a paper on arXiv going into more detail | . | Life and The Second Law by Kai Ueltzhöffer [blog] | Active Inference and Artificial Curiosity by Karl Friston [video] | Predictive Coding Workshop by Karl Friston [video] | A Tutorial on Active Inference by Maxwell Ramstead [video] This is a really well explained intro to both the FEP and active inference. The big bonus is that it includes a great explanation of Markov Blankets, which you’ll definitely want to know about! | . | International Workshop on Active Inference [videos] ECML-PKDD 2020 hosted the first ever International Workshop on Active Inference! This a big deal for the field as a whole, both because active inference got an entire workshop devoted to it at a mainstream machine learning conference, and because created a great space to find more people working in the field! The video tutorials are all available to watch, and come paired with the slideshows. There were too many good talks to list them all, so go check the programme page above! Some talks I particularly enjoyed were: Active Learning and Active Inference in Exploration by Philipp Schwartenbeck | Putting An End to End-to-End: Gradient-Isolated Learning of Representations by Sindy Löwe | On the relationship between active inference and control as inference by Beren Millidge, Alexander Tschantz, Anil Seth and Christopher L. Buckley, and the closely related Active Inference or Control as Inference? A Unifying View by Abraham Imohiosen, Joe Watson and Jan Peters | A Worked Example of Fokker-Planck based Active Inference by Magnus T. Koudahl and Bert de Vries | . | . | . Key papers . This list is as much a list of some of the most fascinating directions of research in the field as it is a general overview. The hope is that the ideas in some of these papers sound so cool that you can’t help but want to take the ideas further (that was my experience, and that’s why I’m still here!). Rereading this list, I can see it’s skewed by my own research interests, so let me know what other sections/papers should be added! . General The Free Energy Principle for Action and Perception: A Mathematical Review by Christopher L. Buckley, Chang Sub Kim, Simon McGregor, Anil K. Seth (2017) If you’re already mathematically trained and just want a good, deep, technical intro to the FEP this is a great paper to start with. It lays almost all of the terminology and main constructs out in one place (notably, it doesn’t introduce Markov Blankets or information geometry) and you’ll be able to read almost every other paper in the FEP literature after reading this! | . | Deep Active Inference by Kai Ueltzhöffer (2017) | A Free Energy Principle for a Particular Physics by Karl Friston (2019) This monograph lays out a sort of grand-unified vision of the FEP as seen from Karl Friston’s point of view. It’s one of the most encompassing of all the FEP papers and I implicitly designed this syllabus so that, if you knew most of the stuff in the prerequisites list, you’d be able to read and understand this | . | . | Reinforcement Learning and Active Inference Reinforcement Learning or Active Inference? by Karl J. Friston, Jean Daunizeau, Stefan J. Kiebel (2009) | Active Inference: Demystified and Compared by Noor Sajid, Philip Ball, Karl J. Friston (2019) | Reinforcement Learning Through Active Inference by Alexander Tschantz, Beren Millidge, Anil K. Seth, Christopher L. Buckley (2020) | Action and Perception as Divergence Minimisation by Danijar Hafner, Pedro A. Ortega, Jimmy Ba, Thomas Parr, Karl Friston, Nicolas Heess (2020) | Active Inference on Discrete State Spaces: A Synthesis by Lancelot Da Costa, Thomas Parr, Noor Sajid, Sebastijan Veselic, Victorita Neacsu, Karl Friston (2020) | . | Physics/Theory The Thermodynamics of Prediction by Susanne Still, David A. Sivak, Anthony J. Bell, Gavin E. Crooks (2012) | Towards A Neuronal Gauge Theory by Biswa Sengupta, Arturo Tozzi, Gerald K. Cooray, Pamela K. Douglas, Karl J. Friston (2016) | Approximate Bayesian inference as a gauge theory by Biswa Sengupta, Karl Friston (2017) | A Tutorial on The Free Energy Framework for Perception and Learning by Rafal Bogacz (2017) | Markov Blankets, Information Geometry, and Stochastic Thermodynamics by Thomas Parr, Lancelot Da Costa, and Karl Friston (2019) | On the statistical mechanics of life: Schrödinger revisited by Kate Jeffery, Robert Pollack, Carlo Rovelli (2019) | Conservation Laws by Virtue of Scale Symmetries in Neural Systems by Erik D. Fagerholm, W. M. C. Foulkes, Yasir Gallero-Salas, Fritjof Helmchen, Karl J. Friston, Rosalyn J. Moran, Robert Leech (2020) | . | Active Inference and Control Theory Active Inference and Agency: Optimal Control without Cost Functions by Karl Friston, Spyridon Samothrakis, and Read Montague (2012) | Active Inference: A Process Theory by Karl Friston, Thomas Fitzgerald, Francesco Rigol, Philipp Schwartenbeck, and Giovanni Pezzulo (2016) | Active inference: building a new bridge between control theory and embodied cognitive science PhD Thesis by Manuel Baltieri (2019) | . | Computational Psychiatry What Is Mood: A Computational Perspective by James Clark, Stuart Watson, and Karl Friston (2018) | Deeply Felt Affect by Casper Hesp, Ryan Smith, Thomas Parr, Micah Allen, Karl Friston, Maxwell Ramstead (2019) | . | Molecular Biology Knowing One’s Place: A Free Energy Approach to Pattern Regulation by Karl Friston, Michael Levin, Biswa Sengupta, and Giovanni Pezzulo (2015) | Morphogenesis as Bayesian inference: A variational approach to pattern formation and control in complex biological systems by Franz Kuchling, Karl Friston, Georgi Georgiev, and Michael Levin (2020) | . | Enactivism and Embodied Cognition A Tale of Two Densities: Active Inference is Enactive Inference by Maxwell Ramstead, Michael Kirchoff, and Karl Friston (2019) This paper was discussed in the Active Inference Live-stream | . | . | Ecological Psychology and Evolution The Active Inference Approach to Ecological Perception: General Information Dynamics for Natural and Artificial Embodied Cognition by Adam Linson, Andy Clark, Subramanian Ramamoorthy, and Karl Friston (2018) | Variational Ecology and the Physics of Sentient Systems by Maxwell Ramstead, Axel Constant, Paul Badcock, and Karl Friston (2019) | The Hierarchically Mechanistic Mind: An Evolutionary Systems Theory of the Human Brain, Cognition, and Behaviour by Paul Badcock, Karl Friston, Maxwell Ramstead, Annemie Ploeger, and Jakob Hohwy | . | Origins of Life/Self-Organisation Life As We Know It by Karl Friston (2013) | Answering Schrodinger’s question: a free-energy formuation by Maxwell Ramstead, Paul Badcock, Karl Friston (2018) | The Markov Blankets of Life: Autonomy, Active Inference, and the Free Energy Principle by Michael Kirchhoff, Thomas Parr, Ensor Palacios, Karl Friston and Julian Kiverstein (2018) | On Markov Blankets and hierarchical self-organisation by Ensor Palacios, Adeel Razi, Thomas Parr, Michael Kirchhoff, Karl Friston (2020) | . | . Open Problems . What are the current open problems in the FEP/Active Inference framework? What research directions are there? Suggestions are encouraged, so comment here or add to this ongoing twitter thread . Conclusion . I hope this encourages more people to get stuck-in to the FEP/Active Inference research-space. It’s so interdisciplinary that it welcomes people from all kinds of backgrounds, and there’s important work that needs doing in math, neurobiology, philosophy, ecology, physics, software engineering, machine learning, and more! There are so many friendly people who are willing to think out loud, explain, answer questions, and offer support - seriously, just try to tweet some of the people mentioned in this post! . Good luck with your studies, and even more so with what you create with that knowledge - perception-and-action are two sides of the same coin, after all! . Contributors . Thanks to these people for suggesting resources to add to the post! . InferenceActive Beren Millidge . . Thank you to Gianluca and @InferenceActive for their helpful comments on drafts of this post! .",
            "url": "https://jaredtumiel.github.io/blog/2020/10/14/spinning-up-in-ai.html",
            "relUrl": "/2020/10/14/spinning-up-in-ai.html",
            "date": " • Oct 14, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Friston's Free Energy Principle Explained (part 1)",
            "content": "The goal of this series of posts is to provide a friendly but rigorous guide to some of the key ideas underlying Karl Friston’s Free Energy Principle (henceforth: FEP). I will provide as much background as possible, and sprinkle in the intuition-pumps I find most helpful. I want this to be a technical guide, so we won’t shy away from any math1. Your reward for making it to the end will be a deep understanding of the core pieces of the Free Energy principle, the ability to explain it to an interested friend in plain english, and the ability to implement a simulation of Active Inference under the Free Energy Principle in Python! But before we get to the Python, we need to lay the groundwork… . By the end of this post you will understand: . Bayesian inference | ‘Phenotype’ as a set of viable states | Entropy and expected surprise | Kullback-Liebler Divergence | Recognition- and Generative-densities | The derivation of the ‘free energy’ term | . Introduction . Karl Friston’s Free Energy Principle has fascinated and baffled me since I first heard about it in a SlateStarCodex blog post2. Ever since, I’ve spent a good chunk of my spare time trying to understand the ideas and context that underpin the theory. Friston’s work is notoriously difficult to understand, something which Friston himself (and definitely the people who read his work) acknowledge with a wry shrug3. This comes down to a few things: . the maths itself is fairly daunting and Friston’s notation can be opaque until you get used to it. But, I’ll show you in this article that it’s not impenetrable and is well worth understanding! | the fields that Friston draws on to derive the FEP are diverse and any given person is unlikely to have studied them all4. I happen to think this is what’s most exciting about the FEP, because it provides an excuse to learn more about: Statistical Mechanics, especially non-equilibrium stat-mech | Reinforcement Learning | Neuroscience and Predictive Coding | Dynamic systems and (stochastic) differential equations | Information theory | Variational inference methods | Path-integral formulations and the Principle of Least Action | Embodied cognition | Bayesian inference, action under uncertainty | Clinical psychiatry and computational corelates of pyschopathology | . | . For this post, don’t worry about that list, as I’ll introduce concepts as we need them! . To begin, let’s look at some motivating ideas, which we’ll keep coming back to, with more and more formalism to back them up. . You: a thing in the world . You are a thing (fully enlightened Buddhists with no sense-of-self don’t @me yet please, it’s just a starting point) and you live in a world which you do not fully understand (or at-least, it should feel that way, if you’re paying any attention to how crazy things are right now). . You get a constant stream of new information through your senses, and your brain somehow needs to use this information-deluge to do things like make exceptional scrambled eggs, renew your driver’s licence, floss your teeth, and other crucial survival-skills. . Eye on the (causal) prize . Our first big insight into the FEP is that if you want to keep doing the survival thing, you should care not about the sense data itself, but about the stuff out there that causes it - you need to keep your eye on the causal prize! The sense data is just receptors firing more or less often. What matters is that you have receptors that reliably fire in a pattern that tells you useful things like: . there’s a tiger there and she looks pissed | it smells like chocolate cookies have just come out the oven, so you might get fed soon | the molten chocolate cookie you just inhaled is scalding your oesophagus and causing long-term scarring | . So your sense-data isn’t random - it has external causes - but it’s not perfectly reliable either. It’s a noisy connection, and ambiguity abounds: . is that a burglar standing in the corner of your dark room, or did someone leave a coat hanging on your hatstand? | is that the rustling of the wind in the leaves, or another, even scarier tiger stalking you? | is the pressure of your ‘deep-tissue sports-massage’ a welcome relief from stiffness, or categorical proof that your masseuse is a sadist? | . Macro-stable, micro-random . In the time you read all of the above, you breathed several times, each of your cells used some ATP, some cells died or were phagocytosed, the state of your brain changed and a bunch of different neurons fired, and yet You are still a thing in the world. From this I infer that you did not suddenly dissolve into an unremarkable puddle of goo in the preceding 30 seconds. This is our second big insight into the FEP: as a system, many little things can change (you are dynamic), but you must keep yourself tightly bound into a larger pattern - you can be micro-random but must be macro-stable!. Friston often refers to this as possessing an ‘attracting set’ - a set of states that all of your bizarre chemical processes can wiggle around in and between, but not out of. . There are lots of ways you could configure all of the atoms that currently constitute ‘you’. Unfortunately, the vast majority are unworkable, probably because the most likely arrangement of those atoms is spread in a thin mist somewhere between here and Neptune. The small subset of all possible ways to configure yourself that keeps you ‘you’ is your phenotype, and homeostasis is basically the process of keeping yourself in those states through feedback and self-regulation. To survive long-term, you need to have a high probability of occupying those states that are compatible with life (and a low probability of becoming a thin mist somewhere between here and Neptune) . Let’s make a concrete example out of temperature… . It’s getting hot in here (and that’s surprising) . Your body keeps itself near 37 degrees (Celsius), all the time5 . If you were suddenly to sense a temperature of 800 degrees, that would be surprising. And bad. As an organism, 800 degrees is not compatible with your continued existence, and is not something your phenotype is equipped to deal with. In this sense, your body is implicitly making a claim that there is a low probability of you experiencing 800 degree heat, because if that were not the case, you would have a different body. Since 37 degrees seems cosy enough, your body itself is an implicit expectation of a high probability of sensing that temperature6. . So your evolved biology ‘expects’ 37 degrees , and when it doesn’t get it it’s surprised. This ‘surprisal’ is actually a formal term from information theory, where we quantify the amount of surprise as the negative natural logarithm of the probability of the observed outcome: . −ln⁡P(X=x)- ln P(X = x)−lnP(X=x) . All this is saying is that the lower the probability we expect for an event, the more surprised we should be if we do in-fact observe that event, and conversely, if we think there is a high probability of an event happening, we should not be very surprised to see it occur. If you enter the lottery, and I tell you you’ve won, you’d be really really surprised, because you know the probability of that is small. If I tell you you’ve lost, you’re not really surprised at all, as that was always the likely outcome. . . Let’s drill a little deeper into this business of sensing something and - on the basis of that sensation - forming accurate beliefs about the temperature of the environment and your body. It’s worth saying: you don’t have a nice digital-thermometer organ attached somewhere to your body which your brain can just look at. You have millions of tiny sensory receptors, which fire because of the energetic bumping and jostling of atoms hitting the receptor. For a temperature receptor, when it’s hotter, the atoms hitting it have a higher average energy, which makes it more likely that the neuron the receptor is attached to is depolarised and fires an action potential (“spikes”). We can roughly reason that in hotter environments, our temperature receptors are firing more often (but only on average - it’s still a “noisy” signal), and so maybe if our brain counted the number of spikes in a certain time, it could learn a mapping from the state of the sensory data it receives to the probable temperature of the environment. . All Reality is Virtual Reality . This gives us our third big clue about the FEP: we don’t directly experience the environment, only the noisy sensations that correlate with it - we’re one layer removed from the world, exploring the virtual reality of our sense data and inferring things about the reality behind it. This is really the jumping off point for the FEP: as an organism, we need to minimise our surprisal (we don’t want to find ourselves in 800 degree heat, and do want to find ourselves at 37 degrees, with high probability), but we only have access to our noisy sense data, and we don’t know what causally determines our temperature in the environment. . Getting Bayesian . As organisms, we want to update our beliefs about the true state of the environment, given some sense data as evidence. That’s right, it’s time for7 . . (obligatory link to Yudkowsky on Bayes Theorem. If this is new, read this now) . Bayes theorem tells us the optimal way to update our beliefs given some new evidence. Doing this is sometimes called Bayesian inference, or Bayesian updating, or - controversially - as “not making up your beliefs”. . . . A brief note on integral notation: I will often write integrals like this: $ int_{}^{}{dx f(x)}$ with the $dx$ at the front of the integral. If you&#39;re used to seeing it at the back, like this: $ int_{}^{} f(x) dx$ don&#39;t freak out, they&#39;re exactly the same. Also, I&#39;m going to leave the bounds of integration out for now. We can add them in if we need them later What we want is to update our belief about the state of the environmental temperature, given our current sensory data. Let’s write the prior probability that our temperature is 37º as $P(T)$, and the probability that we receive 40 incoming neural impulses in a given time as $P(S)$. We want to know the updated probability that our temperature is 37º, given that we sense 40 neural spikes: . P(T∣S)P(T|S)P(T∣S) . So our hypothesis is that the temperature is 37 degrees, and the evidence we’re using to evaluate it is the 40 spikes we received in the last few seconds. . P(T|S)=P(S|T)P(T)P(S)P left( T middle| S right) = frac{P left( S middle| T right)P left( T right)}{ blue{P(S)}}P(T∣S)=P(S)P(S∣T)P(T)​ . . The $ blue{P(S)}$ term seems to cause trouble, so I&#39;m going to spend a little extra time explaining it here, using the example of modelling the weather today based on yesterday&#39;s weather: The probability of it being sunny today, $P( text{Sunny})$ can be thought of as the sum of the two possibilities - it could be sunny today, given that yesterday was sunny, or it could be sunny, given that yesterday was **not** sunny: $$P( text{Sunny}) = P( text{Sunny}| text{sun yesterday})P( text{sun yesterday}) + P( text{Sunny}| text{no sun yesterday})P( text{no sun yesterday})$$ Instead of the sum of these two complementary outcomes, we could sum over each different possibility: $$P( text{Sunny}) = P( text{Sunny}| text{sun})P( text{sun}) + P( text{Sunny}| text{rain})P( text{rain}) + P( text{Sunny|snow})P( text{snow}) + P( text{Sunny|tornado})P( text{tornado}) + ...$$ Which we can compress as a sum over each possible weather state: $$P( text{Sunny}) = sum_{weather}{P( text{Sunny|weather})P( text{weather})}$$ Based on the box above, we want to write $P(S)$ like this: . P(S)=∑iP(S∣Ti)P(Ti) blue{P(S) = sum_{i}{P(S|T_i)P(T_i)}}P(S)=i∑​P(S∣Ti​)P(Ti​) . but we must remember that, unlike our discrete weather states above, temperature is a continuous variable (it’s just a real number, which can take any value). Therefore, we replace the sum over states with an integral over all temperature values: . P(T|S)=P(S|T)P(T)∫P(S|T)P(T)dTP left( T middle| S right) = frac{P left( S middle| T right)P left( T right)}{ blue{ int_{}^{}{P left( S middle| T right)P left( T right) text{dT}}}}P(T∣S)=∫​P(S∣T)P(T)dTP(S∣T)P(T)​ . And there you have it. All you need to do to perfectly understand the world is know the probability of experiencing some sensory data given a particular environmental state, and evaluate the probability of experiencing that sensory data under every possible hypothetical temperature. Very simple stuff! . Okay, so that integral is intractable, which is formal mathematical language for ‘Wolfram Alpha can’t compute it’. This is a problem for the FEP, and much of the rest of our effort will go into getting around that integral. When we can’t get an exact result, we turn to approximate methods. We’re going to manipulate our equation above until it’s in a form that allows us to do approximate Bayesian inference. . Approximating your posterior . We want to find the posterior probability (the probability we get after applying a Bayesian update) that: . P(T=37∣S)P(T=37|S)P(T=37∣S) . It would really help us control our body temperature if we understood the causal influences determining it. Intuitively, we want a world-model that predicts that if we move closer to a heat-source, we’ll get sensory data that tells us we’re getting hotter. . The internal model that encodes how we expect our sense data to correlate with our environmental states is called a Generative Model, and is referred to by Friston as the G-density. Our G-density tells us the joint probability of experiencing some sense data and a corresponding environmental state: P(T,S)P(T,S)P(T,S) . You can imagine this as a big table that assigns a probability to each possible pair of values. A good model in this case would assign a high probability to the combination: . P(high temp, lots of spikes)P( text{high temp, lots of spikes})P(high temp, lots of spikes) . and a low probability to things like: . P(high temp, few spikes)P( text{high temp, few spikes})P(high temp, few spikes) . We will also want a function that represents our current ‘best-guess’ as to the causes of our sensory input, which we’ll call the R-density (for Recognition): q(T)q(T)q(T) . This is just a probability distribution over the state of the environment, and we’re using $q$ instead of $p$ to remind us that it’s a distribution we’re guessing at. . We now need another fancy piece of information theory: the Kullback-Liebler (KL) Divergence8 . The KL Divergence just tells us how different two different probability distributions are: . . We want the KL divergence because we want to know how close or far away our best guess is to the true posterior belief if we could compute that ugly integral . We write the KL-divergence between our guess $q(T)$ about the environment and the optimal posterior belief about the environment from Baye’s theorem: . DKL(q(T)∣∣P(T∣S)) = ∫dT q(T)ln⁡q(T)P(T|S)D_{ text{KL}}(q(T)||P(T|S)) = int_{}^{}{ text{dT} q( T ) ln frac{q left( T right)}{P left( T middle| S right)}}DKL​(q(T)∣∣P(T∣S)) = ∫​dT q(T)lnP(T∣S)q(T)​ . which we rearrange using the property of the logarithm to: . = ∫dT q(T)[ln⁡q(T) − ln⁡P(T∣S)]= int_{}^{}{dT q(T) lbrack ln{q(T) - ln P(T|S) rbrack}}= ∫​dT q(T)[lnq(T) − lnP(T∣S)] . Now, any R-density (that is, any $q(T)$) which minimises this KL divergence, must be a good approximation of our true posterior. The only problem is that we don’t know the true posterior (that’s the thing we’re trying to work out in the first place), and so can’t simply guess a $q(T)$ to see if it minimises the KL Divergence, because we don’t know what we’re comparing it to. . To get around this, we’ll rewrite the true posterior . P(T∣S) orange{P(T|S)}P(T∣S) . using some pretty basic probability theory identities: . P(T∣S)=P(S∣T)P(T)P(S) orange{P( T | S )} = frac{ blue{P( S | T )P( T )}}{ purple{P( S )}}P(T∣S)=P(S)P(S∣T)P(T)​ . P(T,S)=P(S∣T)P(T) blue{P( T,S ) = P( S | T )P( T )}P(T,S)=P(S∣T)P(T) . ∴P(T∣S)=P(T,S)P(S) therefore orange{P( T | S )} = frac{ blue{P( T,S )}}{ purple{P( S )}}∴P(T∣S)=P(S)P(T,S)​ . If we take the natural log of both sides: . ln⁡P(T|S)=ln⁡P(T,S)P(S)=ln⁡P(T,S)−ln⁡P(S) ln{ orange{P left( T middle| S right)}} = ln{ frac{ blue{P left( T,S right)}}{ purple{P left( S right)}} = ln{ blue{P left( T,S right)}} - ln{ purple{P left( S right)}}}lnP(T∣S)=lnP(S)P(T,S)​=lnP(T,S)−lnP(S) . Plugging this expression for $P(T | S)$ into our KL Divergence we get: . DKL(q(T)∣∣P(T∣S)) =∫dT q(T)[ ln⁡q(T)−ln⁡P(T,S)+ln⁡P(S)]D_{ text{KL}}(q(T)|| orange{P(T|S)}) = int_{}^{}{dT q(T) lbrack ln{q left( T right) - ln{ blue{P left( T,S right)} + ln{ purple{P left( S right)}}}}} rbrackDKL​(q(T)∣∣P(T∣S)) =∫​dT q(T)[ lnq(T)−lnP(T,S)+lnP(S)] . Combining the first two $ ln$ terms: . DKL(q(T)∣∣P(T∣S)) =∫dT q(T)[ln⁡q(T)P(T,S) + ln⁡P(S) ]D_{ text{KL}}(q(T)|| orange{P(T|S)}) = int_{}^{}{dT q(T) lbrack ln{ frac{q left( T right)}{ blue{P( T,S)}} + ln{ purple{P left( S right)}} }} rbrackDKL​(q(T)∣∣P(T∣S)) =∫​dT q(T)[lnP(T,S)q(T)​ + lnP(S) ] . Something you may notice about this is that we now have our KL divergence in terms of only our R-density, $q(T)$, and our G-density, $P(T,S)$, plus a ‘surprisal’ term $ ln P(S)$. This looks like progress! Remember, our R density is just our current best guess about the true state of the environment, the G-density is our internal model of how sensory data and environmental states correlate, and surprisal tells us how unexpected some data was! . We can pull the $ ln P(S)$ out from under the integral because integration is linear we’re integrating over $dT$ and so $ ln P(S)$ acts like a constant (it’s just a number): . DKL(q(T)∣∣P(T∣S)) =∫dT q(T) ln⁡q(T)P(T,S) +ln⁡P(S)∫dT q(T)D_{ text{KL}}(q(T)||P(T|S)) = int_{}^{}{ text{dT} q(T) ln{ frac{q left( T right)}{ blue{P( T,S )}} }} + ln{ purple{P(S)}} int_{}^{}{dT q(T)}DKL​(q(T)∣∣P(T∣S)) =∫​dT q(T) lnP(T,S)q(T)​ +lnP(S)∫​dT q(T) . Furthermore, we have the requirement that . ∫dT q(T)=1 green{ int_{}^{}{ text{dT} q left( T right) = 1}}∫​dT q(T)=1 . which just says that the total probability must add to 1. Using this, we get: . DKL(q(T)∣∣P(T∣S)) =∫dT[q(T)ln⁡q(T)P(T,S) ]+ln⁡P(S)×1D_{ text{KL}}(q(T)||P(T|S)) = pink{ int_{}^{} text{dT} left lbrack q left( T right) ln{ frac{q left( T right)}{ blue{P left( T,S right)}} } right rbrack} + ln{ purple{P left( S right)} times green{1}}DKL​(q(T)∣∣P(T∣S)) =∫​dT[q(T)lnP(T,S)q(T)​ ]+lnP(S)×1 . Now, we define: . F ≡∫dT[q(T)ln⁡q(T)P(T,S) ]F equiv pink{ int_{}^{} text{dT} left lbrack q left( T right) ln{ frac{q left( T right)}{ blue{P left( T,S right)}} } right rbrack}F ≡∫​dT[q(T)lnP(T,S)q(T)​ ] . Giving us: . DKL(q(T)∣∣P(T|S))=F+ln⁡P(S)D_{ text{KL}}(q(T)||P left( T middle| S right)) = F + ln{P(S})DKL​(q(T)∣∣P(T∣S))=F+lnP(S) . If you haven’t guessed already, the F we defined above is ‘free energy’!!. Now we have a key result in the Free Energy literature, one which Friston refers to all the time: . Free energy is an upper bound on surprisal! . You can see this if I tell you that the KL divergence has the property that it is always greater than or equal to zero: . DKL(q(T)∣∣P(T|S))≥0D_{ text{KL}}(q(T)||P left( T middle| S right)) geq 0DKL​(q(T)∣∣P(T∣S))≥0 . ⇒F + ln⁡P(S)≥ 0 Rightarrow F + ln{P left( S right)} geq 0⇒F + lnP(S)≥ 0 . F ≥ −ln⁡P(S)F geq - ln{P(S)}F ≥ −lnP(S) . Free energy is the surprisal an organism experiences upon sampling some data, given a generative model. . More specifically, free energy is the surprisal an organism experiences upon sampling some data, given a generative model. If you’re up for it, you should try matching those words to the parts of the equations that encode them! I’ll even put the full equation right here in-front of you, with no distracting colours: . F ≥ −ln⁡P(S)F geq - ln{P(S)}F ≥ −lnP(S) . ∫dT[q(T)ln⁡q(T)P(T,S) ]≥−ln⁡P(S) int_{}^{} text{dT} left lbrack q left( T right) ln{ frac{q left( T right)}{P left( T,S right)} } right rbrack geq - ln P(S)∫​dT[q(T)lnP(T,S)q(T)​ ]≥−lnP(S) . So far, we have found that this quantity ‘free energy’ is an upper bound on surprisal, and we notice that minimising it means we are approximating the true posterior . P(T∣S)P(T|S)P(T∣S) . Another form of the free energy: . We’re going to need to massage this equation for F a bit more to see if something useful pops out. . Again, using the linearity of integration and the properties of the logarithm, we have: . F ≡∫dT[q(T)ln⁡q(T)P(T,S) ]F equiv int_{}^{} text{dT} left lbrack q left( T right) ln{ frac{q left( T right)}{P left( T,S right)} } right rbrackF ≡∫​dT[q(T)lnP(T,S)q(T)​ ] . F = ∫dT q(T) ln⁡q(T)  −∫dT q(T)ln⁡P(T,S)F = int_{}^{} text{dT}{ q(T) ln{q(T) } -} int_{}^{}{ text{dT} q(T) ln{P(T,S)}}F = ∫​dT q(T) lnq(T)  −∫​dT q(T)lnP(T,S) . From statistics, we say that the expected value (or average) of a Random Variable $X$ is the sum over all values that variable can take, times the probability it takes that value: . E[X] = ∑ixiP(X=xi)E lbrack X rbrack = sum_{i}^{}{x_{i}P(X=x_{i})}E[X] = i∑​xi​P(X=xi​) . . If you need a sanity check, let&#39;s compute this for a fair 6-sided die. The probability for each face landing up is $1/6$ The values our random variable $X$ can take are $X = {1,2,3,4,5,6 }$ $$E[X] = sum_{x=1}^{6} frac{1}{6}x = 3.5$$ which is indeed the correct average value for our die 🎲 Replacing the sum with an integral in the continuous case: . E⁡[X]=∫RxP(x) dx displaystyle operatorname {E} [X]= int _{ mathbb {R} }xP(x) ,dxE[X]=∫R​xP(x)dx . We also have the entropy of a system (you should convince yourself that this is the “expected value” of the surprise $- ln P(x)$): . H(X)=−∑i=1nP(xi)log⁡P(xi) mathrm {H} (X)=- sum _{i=1}^{n}{ mathrm {P} (x_{i}) log mathrm {P} (x_{i}})H(X)=−i=1∑n​P(xi​)logP(xi​) . . Entropy can be a somewhat tricky term, but I think this way of thinking about it is fairly intuitive: it’s just the amount you expect to be surprised by a given probability distribution. Some distributions are very tightly clustered around their average values, and so they are very unsurprising, hence low entropy. The opposite of this are the so-called maximum-entropy distributions, which means every sample is maximally surprising. . . An example entropy calculation: A coin is a maximum entropy system, because it&#39;s maximally unpredictable, you don&#39;t know if it&#39;s going to come up heads $h$ or tails $t$ $$H(coin) = -P(h) log P(h) - P(t) log P(t)$$ $$H(coin) = -0.5 * log(0.5) - 0.5 log(0.5)$$ $$H(coin) approx 0.3$$ Now imagine if we had an unfair coin that came up heads with a probability of 90%: $$H(coin) = -P(h) log P(h) - P(t) log P(t)$$ $$H(coin) = -0.9 log (0.9) - 0.1 log (0.1)$$ $$H(coin) approx 0.14$$ So the more certain we are about an outcome, the lower the entropy! Equipped with these ideas, we define an energy-like function $ mathbf{E}(T,S)$: . E(T,S) ≡−ln⁡P(T,S) red{ mathbf{Ε}(T,S)} equiv red{- ln{P(T,S)}}E(T,S) ≡−lnP(T,S) . And this allows us to rewrite our free energy term F as (remember the $ mathbf{E}(T,S)$ is defined as the negative of the log above, so we get a positive in the end): . F =∫dT q(T) ln⁡q(T)  −∫dT q(T)ln⁡P(T,S)F = purple{ int_{}^{}{ text{dT} q(T) ln{q(T) }}} - int_{}^{}{ text{dT} q(T) red{ ln{P(T,S)}}}F =∫​dT q(T) lnq(T)  −∫​dT q(T)lnP(T,S) . F=∫dT q(T)E(T,S)+∫dT q(T)ln⁡q(T)F = int_{}^{}{ text{dT} q left( T right) red{ mathbf{E} left( T,S right)}} + purple{ int_{}^{}{ text{dT} q left( T right) ln{q left( T right)}}}F=∫​dT q(T)E(T,S)+∫​dT q(T)lnq(T) . Now, if we look at this formula (check that you see this from above) it looks like it’s saying that ‘free energy’ is equal to an average (expected value) of the energy-like function, minus something that looks a little like a continuous version of the entropy9. This version of the formula is something you’ll hear Friston refer to often, because it’s analagous to the Helmholtz free energy from thermodynamics/statistical mechanics: $F = U-TS$. The Helmholtz free energy is defined as the difference between the internal energy $U$ and the entropy $S$ of the system, multiplied by the temperature $T$. Here the term ‘free energy’ acquires some physical sense, being the quantity of energy in our system that is available to do useful work. Here I’ve split the $+$ into two negatives to emphasise we have a potential energy minus the entropy. . F=∫dT q(T)E(T,S)−(−∫dT q(T)ln⁡q(T))F = int_{}^{}{ text{dT} q left( T right) mathbf{E} left( T,S right) } - left( - int_{}^{}{ text{dT} q left( T right) ln{q left( T right)} } right)F=∫​dT q(T)E(T,S)−(−∫​dT q(T)lnq(T)) . Having gone through all of the above, we can now state the FEP explicitly: . The Free Energy Principle states that a system in nonequilibrium steady state with its environment must minimise its free energy . We’ll need another few posts to unpack everything there, but at minimum we now know what the ‘free energy’ term is and why minimising it might be useful! . Conclusion, Summary, and Anki Cards . We motivated the Free Energy Principle with three big ideas about living organisms: . Eye on the (causal) prize Survival depends on you figuring out what causes your sense data, because that allows you to model your environment | . | All Reality is Virtual Reality Survival depends on interpreting noisy correlates of the causes you care about. You can’t see the causes directly | . | Macro-pattern, micro-random You are made of atoms doing lots of small, random things, which you must self-regulate to keep within a broader set of viable patterns | . | . Additionally, we learned: . We want to calculate the probability of our environment, given our sense data, but the integral is intractable | We use approximate Bayesian inference to get around this | The G-density is a probability density function that tells us how environmental states correlate with sensations: $P(T,S)$ | The R-density is an internal best guess by the organism about the state of the environment: $q(T)$ | Minimising the KL-Divergence lets us approximate the posterior | Free energy is an upper bound on surprisal | We can rewrite our free energy as an average energy minus an entropy term, which makes it look like the Helmholtz free energy | . As an experiment in what Michael Nielsen and Andy Matuschak dub the Mnemonic Medium, I’ve made a small deck of Anki cards that complement this post. If you use them, they’ll make the tricky vocabulary we’ve developed here into something you have stored in your long-term memory for easy use. You can download them here . In the next post, we’ll take the background we developed here and build on it. We’ll take a deeper look at the R and G densities and some simplifying assumptions that allow us to write neat versions of them. The result will show the deep connection between the Free Energy Principle and Predictive Coding in the brain. . If something here doesn’t make sense, is clearly wrong, or got you interested, let me know here or on twitter @jnearestn If you don’t want to wait for the next post, The Free Energy Principle for Action and Perception: A Mathematical Review is the best place to start out on your own, and I owe it a great deal in helping write this post! . . Special thanks to Gianluca for his detailed comments on drafts of this post . The good news is that the Jeremy Howard rule holds: even if all of the math seems difficult, it will look much simpler in code &#8617; . | shoutout to the New York Times for going full 2020 and trying to ruin that too &#8617; . | See for example Friston’s reaction to a bunch of quants in this article &#8617; . | in fact, this multiplicity of disciplines seems to set off a percentage of people’s BS-detectors, sort of like when Deepak Chopra starts invoking Quantum Mechanics as an explanation for everything &#8617; . | if you don’t like 37, just use whatever number you were told by the last person who pointed one of those COVID-screening-thermometer-guns at your head &#8617; . | there is of course the question of ‘why expect 37 degrees in the first place, why not 800 and then you can survive through more possible states’, to which the quick answer is “evolution” and evolutionary niches” – something like: that temperature is the constraint that you, as a particular organism, are forced to satisfy because of the particular set of biochemical pathways you evolved to best fit into your environmental niche (which seems, at this point, to be Zoom Meetings, for some reason?) &#8617; . | 9 year old Jared knew a killer font when he saw one &#8617; . | watch this video by Aurelien Geron if you want a great intro to the KL-divergence &#8617; . | as I’m writing this, I’m learning that this continuous analogy of the entropy is not actually well-defined. It’s called differential entropy, and Claude Shannon apparently just wrote it down, assuming it was correct (okay, now I feel less bad for making the same assumption). It took E.T Jaynes to write down a better version called the ‘Limiting Density of Discrete Points’, which - at minimum - is a worse name than ‘differential entropy’. I don’t know what effect the ill-definedness of continuous entropy has for the FEP, so that’s something to look into while I write part 2! &#8617; . |",
            "url": "https://jaredtumiel.github.io/blog/2020/08/08/free-energy1.html",
            "relUrl": "/2020/08/08/free-energy1.html",
            "date": " • Aug 8, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Unconventional Ways to Learn More Online",
            "content": "This doesn’t apply to people receiving a set online syllabus from a university or other institution. This is for people who, for whatever reason, didn’t have the chance to take the math/physics/bio/compsi1 courses they wanted to at a university, and are now trying to learn something useful on their own. . 1. Advanced before Introductory . ‘Intro’ courses are everywhere, and they’re largely useless2. They’re fine if you want to keep up with conversation, but they’re too superficial to make your training useful. Coursera and other platforms like it are particularly full of these kinds of courses. . It is an unwritten rule of university professors that every course must begin with an introductory lecture which revises everything you would get from the ‘beginners’ course, so you’ll know if you are missing anything crucial before you begin. Another reason to go for the advanced course is because, bizarrely, introductory courses often end up leaving out exactly the ‘advanced’ arguments that make complex ideas make sense. Advanced courses will keep you interested for longer, because you’ll have to really try to understand. If you can tolerate confusion, being forced to work it out will be more beneficial than comfortably following the boring intro course. . How? . If you’re going to use Coursera, look for an advanced course. Even better, avoid Coursera and find the course a department actually uses to teach its students. There’s an art to this, but if you can find the course’s webpage for students (start at the departments’ webpage, go to a lecturer’s bio and see if it lists any courses), there is often a private YouTube playlist lecture recordings, and PDFs of all lecture slides and readings. . Examples: . University of Toronto Machine Learning Courses Economics and Computing courses by Matt Weinberg . 2. Applications before Abstractions . If you want to learn something interesting, and difficult, it probably comes with a substantial list of prerequisites. Or, you have an intuition that learning [advanced concept X] might be useful in your work/research/Twitter-flame-wars. . This is probably Math. For several reasons, math3 is usually the bottleneck to learning the cool new thing you want to try. Your list of prerequisites might be something like: linear algebra, vector calculus, differential equations, abstract algebra, probability theory, differential geometry etc. . And you, being the kind of person who learns things online for fun, will go and track down all of the best complex analysis courses, and they’ll all be intended for math majors and you’ll be perfectly miserable as the Prof writes down another list of assumptions about the function being holomorphic around p. If you love that kind of rigour, stick with it, but I suspect many people are put off because they just need the tools, for now. . How? . Go find courses which explicitly try to teach the ideas of that abstract discipline to non-experts. The benefit is that the Prof now can’t assume she’s talking only to math majors, which may improve your experience. Bonus points if you learn something about the applied discipline too! . Examples: . Abstract Algebra for Theoretical Computer Scientists Applied Topology for Neuroscience Applied Category Theory . 3. Top-Down before Bottom-Up . There are two ways you can go about learning something difficult – you can start at the bottom and build up: learning the prerequisites and the background details, slowly building up towards the big, useful, important, interesting ideas at the cutting edge of the field – or you can start from the top and dig down: immersing yourself immediately in something big and exciting, which you don’t fully understand yet, but which you’re motivated to keep doing because you’ve seen tangible results. Top-down also keeps you focused on essentials, because you only add detail as is necessary for your understanding. Already know how to multiply matrices, but don’t remember how to find their eigenvalues? Then why sit through an entire linear algebra course? You’ll suddenly find yourself needing to learn about eigenvalues and you can spend an hour on YouTube getting up to speed (Tim Ferriss calls this “just in time, not just in case”). . The fast.ai Deep Learning course is the canonical example here. In the first lesson, you train a deep neural net to recognise several breeds of dogs and cats, at near-cutting-edge level. Over the course, you learn by tinkering with advanced models and learning to play around with the code. It’s probably the closest thing to Legitimate Peripheral Participation I’ve seen in an online course so far. . How? . Following rule 1 and 2 should have already got you a lot of the way here. Look for project-based courses, or see if you can just start with the coolest part of a discipline and pick up the prerequisites as you go. Don’t fall into the trap of spending years “in preparation”, this is probably as bad as only ever doing “introductory” courses. . Examples: . Fast.ai . I don’t have any other good examples to hand, suggestions would be appreciated, and I’ll add them here! . I mostly have experience doing this for STEM domains. These might work for courses in the arts/humanities and so on, but there’s probably something important I’m missing &#8617; . | I think that some introductory programming courses might be exceptions here – or maybe languages generally? &#8617; . | I dream of a world where everyone has a browser plugin which just changes words to their favourite version. All the maths vs mathematics vs math people, all the American ‘-ize’ vs sensible ‘-ise’ people could just get on with it. &#8617; . |",
            "url": "https://jaredtumiel.github.io/blog/2020/05/12/three-rules.html",
            "relUrl": "/2020/05/12/three-rules.html",
            "date": " • May 12, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://jaredtumiel.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://jaredtumiel.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Your Algorithmic Reflection",
            "content": "Most people are aware that algorithms shape their online experience. Some people understand that the algorithms’ underlying incentive is to maximise time spent on-site and number of ad-clicks. Few people know how to use this to their benefit. . The 2016 US election saw the popularisation of the terms “filter bubble” and “fake news”. The first refers to algorithms selectively showing social media content that confirms your existing worldview and systematically excluding all but strawman versions of opposing viewpoints from your feed. The second is a consequence of this: the algorithms will propagate the most polarising, least-nuanced views because these naturally stir reaction and attract clicks. At some point, the view becomes so distorted it’s patently false and yet wildly popular within a filter bubble. I’d flesh this out more, but CGP Grey has a wonderful short video explaining just this, so you should go watch that instead. . The Good, the Bad, and the Ugly of your Algorithmic Reflection . Combatting fake news and filter bubbles is vital, but here I want to ask what these algorithms teach us about ourselves and how we can use this knowledge to our advantage. . YouTube, Facebook, and the rest have spent a lot of money developing machine learning systems that will keep you hooked on their platform. They do this by accumulating information about what you seem to like, showing you some suggestions, learning from your reaction, and repeating the process 1. What each company is racing to do is build the most accurate model of you they can because an accurate model of you gives them the power to predict what you might like in the future. . This is my key argument: . Algorithmic content suggestion is here to stay | Algorithms try to understand your interests, personality, and identity to better serve you content you will enjoy - thus keeping you on-site longer | The way the algorithms do this is by observing your current browsing habits (what you do and don’t click on, what you watch and for how long etc.) and the browsing habits of people ‘like you’ (people engaging with similar things and what else they seem interested in) and building a model of you based on this data 2 | In this way, our newsfeeds and suggestions become a reflection of us - our algorithmic reflection | Therefore, we should act in a way which puts the algorithms to work for us so that what is reflected back to us becomes both aspirational (because it represents us at our best) and self-fulfilling (in that consuming better content will shape us into better people, who thus desire better content). | Contrast this last point with The Unhappy Death-Spiral of social media that plays out as follows: . Open your platform of choice and scroll. The timeline is infinite, the videos on autoplay | Halt! The thumbnail has a cat and the all-caps caption ending in “🔥🔥🔥😂😂” has alerted you to the presence of something important. 41K heart reactions can’t be wrong | Train the algorithms to predict that you value the mundane, the clickbaitey, the controversial-but-lacking-in-nuance | Receive suggestions which fulfill this prophecy, consume them in turn, reinforce the algorithm’s model of you | Minutes pass and accumulate into hours. Bleary eyed and invariably feeling just a little worse about yourself, return to what you were meant to be doing. Bonus if you lament to a friend that you “just don’t have time for hiking or coffee or painting like you used to” | . This is a pattern I have repeated more times than I’m comfortable admitting. It’s something I see my friends do, and it’s something I’m sure most readers have experienced, especially if you’re young enough not to have known a world without social media. . We’re collectively adrift in an ocean of online content and most of us are caught in the doldrums (the latitudes where sailors would spend months trapped, just waiting for a wind - an apt metaphor for the difficulty of escaping the Unhappy Death Spiral above). We find ourselves in these doldrums, directed there by algorithms tasked only with keeping us in the ocean. It’s here that we see our chance of escape, for the algorithms don’t care where in the ocean you are, just that you remain 3. The doldrums are a popular destination for the algorithms to steer you into because they work on just about anyone. To see this effect in action, just look at the kind of content that YouTube shows a first-time user who’s just signed up:4 . A first look - I think the video game and car suggestions are the algorithms’ best guess for 20-something men? . Notice that just based off of my demographics, YouTube’s algorithm has identified some topics and videos they know from experience are likely to get me to stick around. Scrolling down a bit shows these suggestions. You can see my browsing location has made the algorithm select some local Soap Operas for me: . Not exactly Khan Academy, is it . I think the first thing to notice here is just how terrible most of these videos are. Many are clickbaitey; several fall into that strange category of simple things that humans find oddly satisfying, things which abuse some novelty switch deep inside us, like this video of someone testing to see if sharks can detect blood. . . I haven’t watched it, so I don’t know what happens. But 31 million people in the past week have. That’s more people than live in all of Australia. That’s so many people that you could have everyone in Australia watch it and share it with everyone in Puerto Rico and everyone in Slovenia and there would still be a million views unaccounted for. . My point here is not to denigrate content creators. If making this kind of YouTube video is what you do, then by all means continue. My point here is to say that for many people, this kind of content - and its analogues on Facebook, Instagram, and the like - is pushed by algorithms because it easily captures our attention without really improving anything else about us. And once we’ve revealed a weakness for this kind of content, we’re bound to be shown more like it, binding us to an algorithmic reflection of ourselves we don’t really like. My point here is that we can do better! . There’s an oft-repeated quote that you are the average of the five people you’re closest to. There’s another that says “you are what you eat”. We’re treated by algorithms as the average of the five-million people closest to our demographic group and we are being force fed their media-diet. . Creating a better reflection - the case for algorithms . Consider for a second the power of these algorithms. They trawl the vast landscape of new content generated every day and manage to reliably identify the few pieces worth seeing. Of the 500 hours of YouTube videos uploaded every minute of every day, or the half a billion tweets sent daily, you see the tiny fraction that are worth it 5. At least in theory they’re worth watching - in practice they’re often just the most polarising, overstated, and clickbaitey. . Remember though, all the algorithms care about is that you use the site. If you could teach them that showing you content that makes you a reliably better person - in whatever way you want to define that - also keeps you using the site, you suddenly have the resources and technology of the world’s most powerful companies working to find more content that will do that. And as you do this more, you can refine your standards, so that the quality of content continues to rise, bringing you with it. . Suddenly, instead of a feed brimming with garbage, you have a legion of algorithms working tirelessly to pick the most nuanced, thoughtful, reasonable, and long-term-useful content from the morass and deliver it to you. You’ve gone from being collateral damage in the war on attention to purposefully using technology to improve yourself in lasting ways. . Before I go on and explain how to do this, I want to pause here because this is the deeper message of this essay: as new sources of information increase, we will be faced with the very real problem of sorting and prioritising it. For most of human history, we’ve managed this ourselves, but in some areas we’ve reached the limits of what we can reasonably sort 6. This puts us at a tipping point, where we need to increasingly offload the administrative burden of discovering, prioritising, and (increasingly) acting on 7 content to machine learning systems. If we do this without considering what those algorithms are optimising for, we risk handing a large part of our lives to systems not aligned with our terminal goals. Currently, they optimise for our attention and our ad-clicks, and this has given us fake news, political polarisation, and filter bubbles. Currently, we can still trick-or-teach them to show us content that both keeps our attention and fulfills some higher purpose of our own. This is only because time-on-site and consuming useful content are not mutually exclusive. However, the natural descent into clickbait that arises out of the competition for attention should remind us that optimising without thinking about second-order effects inevitably leads to unforeseen consequences. We want algorithms to decrease the time we spend on mindless admin. We need not be mindless in how we get there. . A guide to changing your algorithmic reflection . If you wanted to combat this, you might try some of the following (this guide mostly focuses on YouTube because it’s particularly well suited to long-form content that could lead to real, lasting improvements, but similar actions on Facebook, Instagram, Twitter etc. will also work): . 1. Decide on a direction . Start by deciding on exactly what aspect of yourself you want to improve. This can be pretty general to start because the algorithms will naturally find and explore relevant material for you. All you have to do is make sure you only engage with content relevant to the part of you that you want to develop. . For me, I wanted to learn much more about machine learning and mathematics. I wanted to teach YouTube to find the most useful content about these topics. To keep this separate from my everyday YouTube, I created a new Google account and vowed to use it only for videos that would help me learn more about what I care about. To take away the hassle of remembering to switch between Google accounts, I set up a FireFox container (for Chrome users, this plug-in appears to do something similar, but I haven’t used it). Firefox containers keep all your log-in information separate for different accounts on the same website, like this: . . Note how each instance of YouTube is giving me different recommendations, with the middle one giving the most relevant ones to machine learning. Now you can keep your different online personas separate! . 2. Reset the algorithms . If you don’t want to create a new account, or you want to keep your current one, you can reset what the algorithms suggest for you by deleting some or all of your search and watch history. Simply head here, select ‘Delete Activity by’ and type in the keywords or time interval you want gone. . 3. Bonus - browser plugins that make the internet far better . DF YouTube (Firefox) optionally blocks sidebars, feeds, comments, suggestions at the end of videos | uBlock Origin (Firefox, Chrome) has long been my ad-blocker of choice. It far exceeds AdBlock | StayFocusd (Chrome) is great at blocking websites when you want to focus | Wikiwand is not well known but deserves to be. If you use Wikipedia as much as I do, you’ll appreciate the look and feel this adds! | . Go Forth . Algorithms discover, surface, and propagate the content we see. This is unavoidable - desirable even. Everything you interact with on social media is teaching some system what you and people like you are interested in and value. The reflection of ourselves we currently see in the algorithms and on our feeds is distorted, muddied by what gets clicks. Remove the silt, let the waters settle, then move forward with purpose and direction! . Cover Photo by Alexandre Debiève on Unsplash . Am I really going to throw in 2 CGP Grey references in such close proximity? Yes. Watch this video for a basic overview of how algorithms and your feed play together &#8617; . | For the Bayesians here: think of the people ‘like me’ (and my age and demographic info) as giving a prior probability for what I’ll like, and each piece of content I engage with as updates that refine the model &#8617; . | I view the process of removing yourself from this ocean as a separate (and also incredibly important) venture. For more, Cal Newport’s new book, Digital Minimalism is a great start &#8617; . | I made a dummy account using my real age and demographic, then logged in to YouTube to see what I’d be shown &#8617; . | Seriously, try having a look at YouTube videos with less than 100 views, they’re generally terrible &#8617; . | Do you know anyone who is happy or even content with the amount of email they’re currently receiving? &#8617; . | Think the automatic replies in Gmail or Google Calendar scheduling in your flights after you get your ticket confirmation email &#8617; . |",
            "url": "https://jaredtumiel.github.io/blog/2019/08/11/use-algorithms.html",
            "relUrl": "/2019/08/11/use-algorithms.html",
            "date": " • Aug 11, 2019"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hey, I’m Jared! I’m a medical doctor in South Africa. I’m interested in computational neuroscience, bioelectricity, AI, futurism, techno-optimism, origins of life, and the Free Energy Principle! . Where else to find me . I have a podcast [Apple, Spotify] where I speak with my good friend Gianluca about AI, medicine, and neuroscience. .",
          "url": "https://jaredtumiel.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jaredtumiel.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}